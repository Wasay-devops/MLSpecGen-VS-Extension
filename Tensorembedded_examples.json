[
  {
    "postURL": "",
    "title": "",
    "question": "I have been using the introductory example of matrix multiplication in TensorFlow.\n\npythonCopymatrix1 = tf.constant([[3., 3.]])\nmatrix2 = tf.constant([[2.],[2.]])\nproduct = tf.matmul(matrix1, matrix2)\n\nWhen I print the product, it is displaying it as a Tensor object:\n\npythonCopy\n\nBut how do I know the value of product?\n\nThe following doesn't help:\n\npythonCopyprint product\nTensor(\"MatMul:0\", shape=TensorShape([Dimension(1), Dimension(1)]), dtype=float32)\n\nI know that graphs run on Sessions, but isn't there any way I can check the output of a Tensor object without running the graph in a session?",
    "answer": "The easiest[A] way to evaluate the actual value of a Tensor object is to pass it to the Session.run() method, or call Tensor.eval() when you have a default session (i.e. in a with tf.Session(): block, or see below). In general[B], you cannot print the value of a tensor without running some code in a session.\n\nIf you are experimenting with the programming model, and want an easy way to evaluate tensors, the tf.InteractiveSession lets you open a session at the start of your program, and then use that session for all Tensor.eval() (and Operation.run()) calls. This can be easier in an interactive setting, such as the shell or an IPython notebook, when it's tedious to pass around a Session object everywhere. For example, the following works in a Jupyter notebook:\n\npythonCopywith tf.Session() as sess:  print(product.eval()) \n\nThis might seem silly for such a small expression, but one of the key ideas in Tensorflow 1.x is deferred execution: it's very cheap to build a large and complex expression, and when you want to evaluate it, the back-end (to which you connect with a Session) is able to schedule its execution more efficiently (e.g. executing independent parts in parallel and using GPUs).\n\n[A]: To print the value of a tensor without returning it to your Python program, you can use the tf.print() operator, as Andrzej suggests in another answer. According to the official documentation: \n\n  To make sure the operator runs, users need to pass the produced op to tf.compat.v1.Session's run method, or to use the op as a control dependency for executed ops by specifying with tf.compat.v1.control_dependencies([print_op]), which is printed to standard output. \n\nAlso note that:\n\n  In Jupyter notebooks and colabs, tf.print prints to the notebook cell outputs. It will not write to the notebook kernel's console logs.\n\n[B]: You might be able to use the tf.get_static_value() function to get the constant value of the given tensor if its value is efficiently calculable.",
    "mlApiName": "tf.InteractiveSession,tf.Print,tf.Session,tf.Tensor.eval",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "Dare I even ask? This is such a new technology at this point that I can't find a way to solve this seemingly simple error. The tutorial I'm going over can be found here- http://www.tensorflow.org/tutorials/mnist/pros/index.html#deep-mnist-for-experts\n\nI literally copied and pasted all of the code into IPython Notebook and at the very last chunk of code I get an error.\n\npythonCopy# To train and evaluate it we will use code that is nearly identical to that for the simple one layer SoftMax network above.\n# The differences are that: we will replace the steepest gradient descent optimizer with the more sophisticated ADAM optimizer.\n\ncross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\nsess.run(tf.initialize_all_variables())\nfor i in range(20000):\n    batch = mnist.train.next_batch(50)\n    if i%100 == 0:\n        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n    print \"step %d, training accuracy %g\"%(i, train_accuracy)\n    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\nprint \"test accuracy %g\"%accuracy.eval(feed_dict={\n    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n\nAfter running this code, I receive this error.\n\npythonCopy---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n in ()\n     15 \n     16 print \"test accuracy %g\"%accuracy.eval(feed_dict={\n---> 17     x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n\n/root/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in eval(self, feed_dict, session)\n    403 \n    404     \"\"\"\n--> 405     return _eval_using_default_session(self, feed_dict, self.graph, session)\n    406 \n    407 \n\n/root/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in _eval_using_default_session(tensors, feed_dict, graph, session)\n   2712     session = get_default_session()\n   2713     if session is None:\n-> 2714       raise ValueError(\"Cannot evaluate tensor using eval(): No default \"\n   2715                        \"session is registered. Use 'with \"\n   2716                        \"DefaultSession(sess)' or pass an explicit session to \"\n\nValueError: Cannot evaluate tensor using eval(): No default session is registered. Use 'with DefaultSession(sess)' or pass an explicit session to eval(session=sess)\n\nI thought that I may need to install or reinstall TensorFlow via conda install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl but conda doesn't even know how to install it.\n\nDoes anyone have any idea of how to work around this error?",
    "answer": "I figured it out. As you see in the value error, it says No default session is registered. Use 'with DefaultSession(sess)' or pass an explicit session to eval(session=sess) so the answer I came up with is to pass an explicit session to eval, just like it says. Here is where I made the changes.\n\npythonCopyif i%100 == 0:\n        train_accuracy = accuracy.eval(session=sess, feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n\nAnd\n\npythonCopytrain_step.run(session=sess, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\nNow the code is working fine.",
    "mlApiName": "tf.InteractiveSession,tf.Session.run,tf.Tensor.eval",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am trying to implement a simple feed forward network. However, I can't figure out how to feed a Placeholder. This example:\n\npythonCopyimport tensorflow as tf\n\nnum_input  = 2\nnum_hidden = 3\nnum_output = 2\n\nx  = tf.placeholder(\"float\", [num_input, 1])\nW_hidden = tf.Variable(tf.zeros([num_hidden, num_input]))\nW_out    = tf.Variable(tf.zeros([num_output, num_hidden]))\nb_hidden = tf.Variable(tf.zeros([num_hidden]))\nb_out    = tf.Variable(tf.zeros([num_output]))\n\nh = tf.nn.softmax(tf.matmul(W_hidden,x) + b_hidden)\n\nsess = tf.Session()\n\nwith sess.as_default():\n    print h.eval()\n\nGives me the following error:\n\npythonCopy  ...\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 419, in _do_run\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape dim { size: 2 } dim { size: 1 }\n     [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[2,1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Placeholder', defined at:\n  File \"/home/sfalk/workspace/SemEval2016/java/semeval2016-python/slot1_tf.py\", line 8, in \n    x  = tf.placeholder(\"float\", [num_input, 1])\n  ...\n\nI have tried\n\npythonCopytf.assign([tf.Variable(1.0), tf.Variable(1.0)], x)\ntf.assign([1.0, 1.0], x)\n\nbut that does not work apparently.",
    "answer": "To feed a placeholder, you use the feed_dict argument to Session.run() (or Tensor.eval()). Let's say you have the following graph, with a placeholder:\n\npythonCopyx = tf.placeholder(tf.float32, shape=[2, 2])\ny = tf.constant([[1.0, 1.0], [0.0, 1.0]])\nz = tf.matmul(x, y)\n\nIf you want to evaluate z, you must feed a value for x. You can do this as follows:\n\npythonCopysess = tf.Session()\nprint sess.run(z, feed_dict={x: [[3.0, 4.0], [5.0, 6.0]]})\n\nFor more information, see the documentation on feeding.",
    "mlApiName": "tf.Session.run,tf.Tensor.eval",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "IC-1",
      "leafContractCategory": "SAM(Level-3)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am using TensorFlow to train a neural network. This is how I am initializing the GradientDescentOptimizer:\n\npythonCopyinit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n\nmse        = tf.reduce_mean(tf.square(out - out_))\ntrain_step = tf.train.GradientDescentOptimizer(0.3).minimize(mse)\n\nThe thing here is that I don't know how to set an update rule for the learning rate or a decay value for that. \n\nHow can I use an adaptive learning rate here?",
    "answer": "First of all, tf.train.GradientDescentOptimizer is designed to use a constant learning rate for all variables in all steps. TensorFlow also provides out-of-the-box adaptive optimizers including the tf.train.AdagradOptimizer and the tf.train.AdamOptimizer, and these can be used as drop-in replacements.\n\nHowever, if you want to control the learning rate with otherwise-vanilla gradient descent, you can take advantage of the fact that the learning_rate argument to the tf.train.GradientDescentOptimizer constructor can be a Tensor object. This allows you to compute a different value for the learning rate in each step, for example:\n\npythonCopylearning_rate = tf.placeholder(tf.float32, shape=[])\n# ...\ntrain_step = tf.train.GradientDescentOptimizer(\n    learning_rate=learning_rate).minimize(mse)\n\nsess = tf.Session()\n\n# Feed different values for learning rate to each training step.\nsess.run(train_step, feed_dict={learning_rate: 0.1})\nsess.run(train_step, feed_dict={learning_rate: 0.1})\nsess.run(train_step, feed_dict={learning_rate: 0.01})\nsess.run(train_step, feed_dict={learning_rate: 0.01})\n\nAlternatively, you could create a scalar tf.Variable that holds the learning rate, and assign it each time you want to change the learning rate.",
    "mlApiName": "tf.Session.run,tf.train.GradientDescentOptimizer",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,MT",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am  adapting the cifar10 convolution example to my problem.  I'd like to change the data input from a design that reads images one-at-a-time from a file to a design that operates on an already-in-memory set of images.  The original inputs() function looks like this:\n\npythonCopyread_input = cifar10_input.read_cifar10(filename_queue)\nreshaped_image = tf.cast(read_input.uint8image, tf.float32)\n# Crop the central [height, width] of the image.\nresized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n                                                     width, height)\n\nIn the original version, read_input is a tensor containing one image.\n\nI keep all my images in RAM, so instead of using filename_queue, I have one huge images_tensor = tf.constant(images), where images_tensor.shape is (something, 32, 32, 3).\n\nMy question is very-very basic:  what is the best way to apply some function (tf.image.resize_image_with_crop_or_pad in my case) to all elements of  images_tensor? \n\nIterating is problematic in tensorflow, with limited slices(TensorFlow - numpy-like tensor indexing).  Is there a solution to achieving this using just one command?",
    "answer": "As of version 0.8 there is map_fn. From the documentation:\n\nmap_fn(fn, elems, dtype=None, parallel_iterations=10, back_prop=True,\nswap_memory=False, name=None)\n\nmap on the list of tensors unpacked from elems on dimension 0.\n\nThis map operator repeatedly applies the callable fn to a sequence of elements from first to last. The elements are made of the tensors unpacked from elems. dtype is the data type of the return value of fn. Users must provide dtype if it is different from the data type of elems.\n\nSuppose that elems is unpacked into values, a list of tensors. The shape of the result tensor is [len(values)] + fn(values[0]).shape.\n\nArgs:\n\nfn: The callable to be performed.\n\nelems: A tensor to be unpacked to apply fn.\n\ndtype: (optional) The output type of fn.\n\nparallel_iterations: (optional) The number of iterations allowed to run\nin parallel.\nback_prop: (optional) True enables back propagation.\nswap_memory: (optional) True enables GPU-CPU memory swapping.\nname: (optional) Name prefix for the returned tensors.\n\nReturns:\n\nA tensor that packs the results of applying fn to the list of tensors\nunpacked from elems, from first to last.\n\nRaises:\n\nTypeError: if fn is not callable.\n\nExample:\n\npythonCopy  elems = [1, 2, 3, 4, 5, 6]\n  squares = map_fn(lambda x: x * x, elems)\n  # squares == [1, 4, 9, 16, 25, 36]\n  ```",
    "mlApiName": " tf.FIFOQueue.dequeue , tf.FIFOQueue.enqueue_many,tf.image.resize_image_with_crop_or_pad",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm porting my Caffe network over to TensorFlow but it doesn't seem to have xavier initialization. I'm using truncated_normal but this seems to be making it a lot harder to train.",
    "answer": "Since version 0.8 there is a Xavier initializer, see here for the docs.\n\nYou can use something like this:\n\npythonCopyW = tf.get_variable(\"W\", shape=[784, 256],\n           initializer=tf.contrib.layers.xavier_initializer())",
    "mlApiName": "tf.get_variable",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm trying to pass a list into feed_dict, however I'm having trouble doing so. Say I have:\n\npythonCopyinputs = 10 * [tf.placeholder(tf.float32, shape=(batch_size, input_size))]\n\nwhere inputs is fed into some function outputs that I want to compute. So to run this in tensorflow, I created a session and ran the following:\n\npythonCopysess.run(outputs, feed_dict = {inputs: data}) \n#data is my list of inputs, which is also of length 10\n\nbut I get an error, TypeError: unhashable type: 'list'.\nHowever, I'm able to pass the data element-wise like so:\n\npythonCopysess.run(outputs, feed_dict = {inputs[0]: data[0], ..., inputs[9]: data[9]}) \n\nSo I'm wondering if there's a way I can solve this issue. I've also tried to construct a dictionary(using a for loop), however this results in a dictionary with a single element, where they key is: \ntensorflow.python.framework.ops.Tensor at 0x107594a10",
    "answer": "There are two issues that are causing problems here:\n\nThe first issue is that the Session.run() call only accepts a small number of types as the keys of the feed_dict. In particular, lists of tensors are not supported as keys, so you have to put each tensor as a separate key.* One convenient way to do this is using a dictionary comprehension:\n\npythonCopyinputs = [tf.placeholder(...), ...]\ndata = [np.array(...), ...]\nsess.run(y, feed_dict={i: d for i, d in zip(inputs, data)})\n\nThe second issue is that the 10 * [tf.placeholder(...)] syntax in Python creates a list with ten elements, where each element is the same tensor object (i.e. has the same name property, the same id property, and is reference-identical if you compare two elements from the list using inputs[i] is inputs[j]). This explains why, when you tried to create a dictionary using the list elements as keys, you ended up with a dictionary with a single element - because all of the list elements were identical.\n\nTo create 10 different placeholder tensors, as you intended, you should instead do the following:\n\npythonCopyinputs = [tf.placeholder(tf.float32, shape=(batch_size, input_size))\n          for _ in xrange(10)]\n\nIf you print the elements of this list, you'll see that each element is a tensor with a different name.\n\nEDIT: * You can now pass tuples as the keys of a feed_dict, because these may be used as dictionary keys.",
    "mlApiName": "tf.Session.run",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "So suppose I have a tensor \n\npythonCopyX = tf.placeholder(\"float\", [None, 5])\n\nSo that I know the number of columns but not the number of rows. I need to initialize a vector of ones of dimension nrows x 1\n\nNow the following block of code does not work,\n\npythonCopyo = tf.ones(shape=(tf.shape(X)[0], 1))\n==> TypeError: List of Tensors when single Tensor expected\n\nNor does,\n\npythonCopyo = tf.ones(shape=(X.get_shape()[0].value, 1))\n==> TypeError: Input 'dims' of 'Fill' Op has type \n    string that does not match expected type of int32.\n\nNow, I have found that one way to get around this is to actually make my vector of ones a placeholder,\n\npythonCopyo = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n\nAnd to pass in a numpy array of ones of appropriate size in my feed_dict. But this solution strikes me as inelegant and not the intended use of a placeholder. I could be wrong here, but surely there's a better way.",
    "answer": "The way to solve your problem is to use tf.pack operation:\n\no = tf.ones(shape=tf.pack([tf.shape(X)[0], 1]))\n\nThe reason you had errors is that TensorFlow shape is expected to be a list of integers or a tensor link. tf.pack makes it easy to convert a list of integers and/or TensorFlow scalars into a Tensor object.",
    "mlApiName": "tf.ones",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I want to make a trivial neural network, it should just implement the XOR gate. I am using the TensorFlow library, in python. \nFor an XOR gate, the only data I train with, is the complete truth table, that should be enough right? Over optimization is what I will expect to happen very quickly. Problem with the code is that the weights and biases do not update. Somehow it still gives me 100% accuracy with zero for the biases and weights.\n\npythonCopyx = tf.placeholder(\"float\", [None, 2])\nW = tf.Variable(tf.zeros([2,2]))\nb = tf.Variable(tf.zeros([2]))\n\ny = tf.nn.softmax(tf.matmul(x,W) + b)\n\ny_ = tf.placeholder(\"float\", [None,1])\n\nprint \"Done init\"\n\ncross_entropy = -tf.reduce_sum(y_*tf.log(y))\ntrain_step = tf.train.GradientDescentOptimizer(0.75).minimize(cross_entropy)\n\nprint \"Done loading vars\"\n\ninit = tf.initialize_all_variables()\nprint \"Done: Initializing variables\"\n\nsess = tf.Session()\nsess.run(init)\nprint \"Done: Session started\"\n\nxTrain = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\nyTrain = np.array([[1], [0], [0], [0]])\n\nacc=0.0\nwhile acc<0.85:\n  for i in range(500):\n      sess.run(train_step, feed_dict={x: xTrain, y_: yTrain})\n\n  print b.eval(sess)\n  print W.eval(sess)\n\n  print \"Done training\"\n\n  correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n\n  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n  print \"Result:\"\n  acc= sess.run(accuracy, feed_dict={x: xTrain, y_: yTrain})\n  print acc\n\nB0 = b.eval(sess)[0]\nB1 = b.eval(sess)[1]\nW00 = W.eval(sess)[0][0]\nW01 = W.eval(sess)[0][1]\nW10 = W.eval(sess)[1][0]\nW11 = W.eval(sess)[1][1]\n\nfor A,B in product([0,1],[0,1]):\n  top = W00*A + W01*A + B0\n  bottom = W10*B + W11*B + B1\n  print \"A:\",A,\" B:\",B\n  # print \"Top\",top,\" Bottom: \", bottom\n  print \"Sum:\",top+bottom\n\nI am following the tutorial from http://tensorflow.org/tutorials/mnist/beginners/index.md#softmax_regressions\nand in the final for-loop I am printing the results form the matrix(as described in the link).\n\nCan anybody point out my error and what I should do to fix it?",
    "answer": "There are a few issues with your program. \n\nThe first issue is that the function you're learning isn't XOR - it's NOR. The lines:\n\npythonCopyxTrain = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\nyTrain = np.array([[1], [0], [0], [0]])\n\n...should be:\n\npythonCopyxTrain = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\nyTrain = np.array([[0], [1], [1], [0]])\n\nThe next big issue is that the network you've designed isn't capable of learning XOR. You'll need to use a non-linear function (such as tf.nn.relu() and define at least one more layer to learn the XOR function. For example:\n\npythonCopyx = tf.placeholder(\"float\", [None, 2])\nW_hidden = tf.Variable(...)\nb_hidden = tf.Variable(...)\nhidden = tf.nn.relu(tf.matmul(x, W_hidden) + b_hidden)\n\nW_logits = tf.Variable(...)\nb_logits = tf.Variable(...)\nlogits = tf.matmul(hidden, W_logits) + b_logits\n\nA further issue is that initializing the weights to zero will prevent your network from training. Typically, you should initialize your weights randomly, and your biases to zero. Here's one popular way to do it:\n\npythonCopyHIDDEN_NODES = 2\n\nW_hidden = tf.Variable(tf.truncated_normal([2, HIDDEN_NODES], stddev=1./math.sqrt(2)))\nb_hidden = tf.Variable(tf.zeros([HIDDEN_NODES]))\n\nW_logits = tf.Variable(tf.truncated_normal([HIDDEN_NODES, 2], stddev=1./math.sqrt(HIDDEN_NODES)))\nb_logits = tf.Variable(tf.zeros([2]))\n\nPutting it all together, and using TensorFlow routines for cross-entropy (with a one-hot encoding of yTrain for convenience), here's a program that learns XOR:\n\npythonCopyimport math\nimport tensorflow as tf\nimport numpy as np\n\nHIDDEN_NODES = 10\n\nx = tf.placeholder(tf.float32, [None, 2])\nW_hidden = tf.Variable(tf.truncated_normal([2, HIDDEN_NODES], stddev=1./math.sqrt(2)))\nb_hidden = tf.Variable(tf.zeros([HIDDEN_NODES]))\nhidden = tf.nn.relu(tf.matmul(x, W_hidden) + b_hidden)\n\nW_logits = tf.Variable(tf.truncated_normal([HIDDEN_NODES, 2], stddev=1./math.sqrt(HIDDEN_NODES)))\nb_logits = tf.Variable(tf.zeros([2]))\nlogits = tf.matmul(hidden, W_logits) + b_logits\n\ny = tf.nn.softmax(logits)\n\ny_input = tf.placeholder(tf.float32, [None, 2])\n\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, y_input)\nloss = tf.reduce_mean(cross_entropy)\n\ntrain_op = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n\ninit_op = tf.initialize_all_variables()\n\nsess = tf.Session()\nsess.run(init_op)\n\nxTrain = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\nyTrain = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])\n\nfor i in xrange(500):\n  _, loss_val = sess.run([train_op, loss], feed_dict={x: xTrain, y_input: yTrain})\n\n  if i % 10 == 0:\n    print \"Step:\", i, \"Current loss:\", loss_val\n    for x_input in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n      print x_input, sess.run(y, feed_dict={x: [x_input]})\n\nNote that this is probably not the most efficient neural network for computing XOR, so suggestions for tweaking the parameters are welcome!",
    "mlApiName": "tf.nn",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm trying to understand the seq2seq models defined in seq2seq.py in tensorflow. I use bits of code I copy from the translate.py example that comes with tensorflow. I keep getting the same error and really do not understand where it comes from.\n\nA minimal code example to reproduce the error:\n\npythonCopyimport tensorflow as tf\nfrom tensorflow.models.rnn import rnn_cell\nfrom tensorflow.models.rnn import seq2seq\n\nencoder_inputs = []\ndecoder_inputs = []\nfor i in xrange(350):  \n    encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n                                              name=\"encoder{0}\".format(i)))\n\nfor i in xrange(45):\n    decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n                                         name=\"decoder{0}\".format(i)))\n\nmodel = seq2seq.basic_rnn_seq2seq(encoder_inputs,\n                                  decoder_inputs,rnn_cell.BasicLSTMCell(512))\n\nThe error I get when evaluating the last line (I evaluated it interactively in the python interpreter):\n\npythonCopy    >>>  Traceback (most recent call last):\n      File \"\", line 1, in \n      File \"/tmp/py1053173el\", line 12, in \n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/seq2seq.py\", line 82, in basic_rnn_seq2seq\n        _, enc_states = rnn.rnn(cell, encoder_inputs, dtype=dtype)\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/rnn.py\", line 85, in rnn\n        output_state = cell(input_, state)\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/rnn_cell.py\", line 161, in __call__\n        concat = linear.linear([inputs, h], 4 * self._num_units, True)\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/linear.py\", line 32, in linear\n        raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n    ValueError: Linear is expecting 2D arguments: [[None], [None, 512]]\n\nI suspect the error comes from my side :)\nOn a sidenote. The documentation and the tutorials are really great but the example code for the sequence to sequence model (the english to french translation example) is quite dense. You also have to jump a lot between files to understand what's going on. Me at least got lost several times in the code.\n\nA minimal example (perhaps on some toy data) of constructing and training a basic seq2seq model would really be helpful here. Somebody know if this already exist somewhere?\n\nEDIT\nI have fixed the code above according @Ishamael suggestions (meaning, no errors returns) (see below), but there are still some things not clear in this fixed version. My input is a sequence of vectors of length 2 of real valued values. And my output is a sequence of binary vectors of length 22. Should my tf.placeholder code not look like the following? (EDIT yes)\n\npythonCopytf.placeholder(tf.float32, shape=[None,2],name=\"encoder{0}\".format(i))\ntf.placeholder(tf.float32, shape=[None,22],name=\"encoder{0}\".format(i))\n\nI also had to change tf.int32 to tf.float32 above. Since my output is binary. Should this not be tf.int32 for the tf.placeholder of my decoder? But tensorflow complains again if I do this. I'm not sure what the reasoning is behind this.\n\nThe size of my hidden layer is 512 here.\n\nthe complete fixed code\n\npythonCopyimport tensorflow as tf\nfrom tensorflow.models.rnn import rnn_cell\nfrom tensorflow.models.rnn import seq2seq\n\nencoder_inputs = []\ndecoder_inputs = []\nfor i in xrange(350):  \n    encoder_inputs.append(tf.placeholder(tf.float32, shape=[None,512],\n                                          name=\"encoder{0}\".format(i)))\n\nfor i in xrange(45):\n    decoder_inputs.append(tf.placeholder(tf.float32, shape=[None,512],\n                                         name=\"decoder{0}\".format(i)))\n\nmodel = seq2seq.basic_rnn_seq2seq(encoder_inputs,\n                                  decoder_inputs,rnn_cell.BasicLSTMCell(512))",
    "answer": "Most of the models (seq2seq is not an exception) expect their input to be in batches, so if the shape of your logical input is [n], then a shape of a tensor you will be using as an input to your model should be [batch_size x n]. In practice the first dimension of the shape is usually left out as None and inferred to be the batch size at runtime.\n\nSince the logical input to seq2seq is a vector of numbers, the actual tensor shape should be [None, input_sequence_length]. So fixed code would look along the lines of:\n\npythonCopyinput_sequence_length = 2; # the length of one vector in your input sequence\n\nfor i in xrange(350):  \n    encoder_inputs.append(tf.placeholder(tf.int32, shape=[None, input_sequence_length],\n                                              name=\"encoder{0}\".format(i)))\n\n(and then the same for the decoder)",
    "mlApiName": "tf.models.rnn.seq2seq.basic_rnn_seq2seq",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I've got a bunch of images in a format similar to Cifar10 (binary file, size = 96*96*3 bytes per image), one image after another (STL-10 dataset). The file I'm opening has 138MB.\n\nI tried to read & check the contents of the Tensors containing the images to be sure that the reading is done right, however I have two questions - \n\nDoes the FixedLengthRecordReader load the whole file, however just provide inputs one at a time? Since reading the first size bytes should be relatively fast. However, the code takes about two minutes to run. \nHow to get the actual image contents in a displayable format, or display them internally to validate that the images are read well? I did sess.run(uint8image), however the result is empty.\n\nThe code is below:\n\npythonCopyimport tensorflow as tf\ndef read_stl10(filename_queue):\n  class STL10Record(object):\n    pass\n  result = STL10Record()\n\n  result.height = 96\n  result.width = 96\n  result.depth = 3\n  image_bytes = result.height * result.width * result.depth\n  record_bytes = image_bytes\n\n  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n  result.key, value = reader.read(filename_queue)\n  print value\n  record_bytes = tf.decode_raw(value, tf.uint8)\n\n  depth_major = tf.reshape(tf.slice(record_bytes, [0], [image_bytes]),\n                       [result.depth, result.height, result.width])\n  result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n  return result\n# probably a hack since I should've provided a string tensor\n\nfilename_queue = tf.train.string_input_producer(['./data/train_X'])\nimage = read_stl10(filename_queue)\n\nprint image.uint8image\nwith tf.Session() as sess:\n  result = sess.run(image.uint8image)\n  print result, type(result)\n\nOutput:\n\npythonCopyTensor(\"ReaderRead:1\", shape=TensorShape([]), dtype=string)\nTensor(\"transpose:0\", shape=TensorShape([Dimension(96), Dimension(96), Dimension(3)]), dtype=uint8)\nI tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4\nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4\n[empty line for last print]\nProcess finished with exit code 137\n\nI'm running this on my CPU, if that adds anything.\n\nEDIT: I found the pure TensorFlow solution thanks to Rosa. Apparently, when using the string_input_producer, in order to see the results, you need to initialize the queue runners. \nThe only required thing to add to the code above is the second line from below:\n\npythonCopy...\nwith tf.Session() as sess:\n    tf.train.start_queue_runners(sess=sess)\n...\n\nAfterwards, the image in the result can be displayed with matplotlib.pyplot.imshow(result). I hope this helps someone. If you have any further questions, feel free to ask me or check the link in Rosa's answer.",
    "answer": "Just to give a complete answer:\n\npythonCopyfilename_queue = tf.train.string_input_producer(['/Users/HANEL/Desktop/tf.png']) #  list of files to read\n\nreader = tf.WholeFileReader()\nkey, value = reader.read(filename_queue)\n\nmy_img = tf.image.decode_png(value) # use png or jpg decoder based on your files.\n\ninit_op = tf.global_variables_initializer()\nwith tf.Session() as sess:\n  sess.run(init_op)\n\n  # Start populating the filename queue.\n\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(coord=coord)\n\n  for i in range(1): #length of your filename list\n    image = my_img.eval() #here is your image Tensor :) \n\n  print(image.shape)\n  Image.fromarray(np.asarray(image)).show()\n\n  coord.request_stop()\n  coord.join(threads)\n\nOr if you have a directory of images you can add them all via this Github source file\n\n@mttk and @salvador-dali: I hope it is what you need",
    "mlApiName": "tf.Session.run,tf.train.start_queue_runners,tf.train.string_input_producer",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am experimenting with some simple models in tensorflow, including one that looks very similar to the first MNIST for ML Beginners example, but with a somewhat larger dimensionality. I am able to use the gradient descent optimizer with no problems, getting good enough convergence. When I try to use the ADAM optimizer, I get errors like this:\n\npythonCopytensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value Variable_21/Adam\n     [[Node: Adam_2/update_Variable_21/ApplyAdam = ApplyAdam[T=DT_FLOAT, use_locking=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_21, Variable_21/Adam, Variable_21/Adam_1, beta1_power_2, beta2_power_2, Adam_2/learning_rate, Adam_2/beta1, Adam_2/beta2, Adam_2/epsilon, gradients_11/add_10_grad/tuple/control_dependency_1)]]\n\nwhere the specific variable that complains about being uninitialized changes depending on the run. What does this error mean? And what does it suggest is wrong? It seems to occur regardless of the learning rate I use.",
    "answer": "The AdamOptimizer class creates additional variables, called \"slots\", to hold values for the \"m\" and \"v\" accumulators.\n\nSee the source here if you're curious, it's actually quite readable:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/adam.py#L39 . Other optimizers, such as Momentum and Adagrad use slots too.\n\nThese variables must be initialized before you can train a model.\n\nThe normal way to initialize variables is to call tf.initialize_all_variables() which adds ops to initialize the variables present in the graph when it is called.\n\n(Aside: unlike its name suggests, initialize_all_variables() does not initialize anything, it only add ops that will initialize the variables when run.)\n\nWhat you must do is call initialize_all_variables() after you have added the optimizer:\n\npythonCopy...build your model...\n# Add the optimizer\ntrain_op = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n# Add the ops to initialize variables.  These will include \n# the optimizer slots added by AdamOptimizer().\ninit_op = tf.initialize_all_variables()\n\n# launch the graph in a session\nsess = tf.Session()\n# Actually intialize the variables\nsess.run(init_op)\n# now train your model\nfor ...:\n  sess.run(train_op)",
    "mlApiName": "tf.initialize_all_variables,tf.train.AdamOptimizer",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am trying to assign a new value to a tensorflow variable in python.\n\npythonCopyimport tensorflow as tf\nimport numpy as np\n\nx = tf.Variable(0)\ninit = tf.initialize_all_variables()\nsess = tf.InteractiveSession()\nsess.run(init)\n\nprint(x.eval())\n\nx.assign(1)\nprint(x.eval())\n\nBut the output I get is\n\npythonCopy0\n0\n\nSo the value has not changed. What am I missing?",
    "answer": "In TF1, the statement x.assign(1) does not actually assign the value 1 to x, but rather creates a tf.Operation that you have to explicitly run to update the variable.* A call to Operation.run() or Session.run() can be used to run the operation:\n\npythonCopyassign_op = x.assign(1)\nsess.run(assign_op)  # or `assign_op.op.run()`\nprint(x.eval())\n# ==> 1\n\n(* In fact, it returns a tf.Tensor, corresponding to the updated value of the variable, to make it easier to chain assignments.)\n\nHowever, in TF2 x.assign(1) will now assign the value eagerly:\n\npythonCopyx.assign(1)\nprint(x.numpy())\n# ==> 1",
    "mlApiName": "tf.Session.run,tf.Variable.assign",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I have a deep neural network where the weights between layers are stored in a list. \n\nlayers[j].weights I want to incluse the ridge penalty in my cost function. I need then to use something like \ntf.nn.l2_loss(layers[j].weights**2 for j in range(self.n_layers)) i.e. the squared sum of all the weights. \n\nIn particular the weights are defined as:\n\npythonCopy>>> avs.layers\n[, , , , , , ]\n>>>\n>>> avs.layers[0].weights\n\n>>> \n\nHow can I do that in tensorflow ?",
    "answer": "The standard way to sum a list of tensors is to use the tf.add_n() operation, which takes a list of tensors (each having the same size and shape) and produces a single tensor containing the sum.\n\nFor the particular problem that you have, I am assuming that each layers[j].weights could have a different size. Therefore you will need reduce each element down to a scalar before summing, e.g. using the tf.nn.l2_loss() function itself:\n\npythonCopyweights = [layers[j].weights for j in range(self.n_layers)]\nlosses = [tf.nn.l2_loss(w) for w in weights]\ntotal_loss = tf.add_n(losses)\n\n(Note however that when the values to be added are large, you may find it more efficient to calculate a sequence of tf.add() operations, since TensorFlow keeps the values of each of the add_n arguments in memory until all of them have been computed. A chain of add ops allows some of the computation to happen earlier.)",
    "mlApiName": " tf.add_n, tf.nn.l2_loss",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am trying to generate a random variable and use it twice. However, when I use it the second time, the generator creates a second random variable that is not identical to the first. Here is code to demonstrate:\n\npythonCopyimport numpy as np\nimport tensorflow as tf\n\n# A random variable\nrand_var_1 = tf.random_uniform([5],0,10, dtype = tf.int32, seed = 0)\nrand_var_2 = tf.random_uniform([5],0,10, dtype = tf.int32, seed = 0)\n\n#Op1\nz1 = tf.add(rand_var_1,rand_var_2)\n\n#Op2\nz2 = tf.add(rand_var_1,rand_var_2)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    z1_op = sess.run(z1)\n    z2_op = sess.run(z2)\n    print(z1_op,z2_op)\n\nI want z1_op and z2_op to be equal. I think this is because the random_uniform op gets called twice. Is there a way to use TensorFlow (without using NumPy) to achieve this? \n\n(My use case is more complicated, but this is the distilled question.)",
    "answer": "The current version of your code will randomly generate a new value for rand_var_1 and rand_var_2 on each call to sess.run() (although since you set the seed to 0, they will have the same value within a single call to sess.run()).\n\nIf you want to retain the value of a randomly-generated tensor for later use, you should assign it to a tf.Variable:\n\npythonCopyrand_var_1 = tf.Variable(tf.random_uniform([5], 0, 10, dtype=tf.int32, seed=0))\nrand_var_2 = tf.Variable(tf.random_uniform([5], 0, 10, dtype=tf.int32, seed=0))\n\n# Or, alternatively:\nrand_var_1 = tf.Variable(tf.random_uniform([5], 0, 10, dtype=tf.int32, seed=0))\nrand_var_2 = tf.Variable(rand_var_1.initialized_value())\n\n# Or, alternatively:\nrand_t = tf.random_uniform([5], 0, 10, dtype=tf.int32, seed=0)\nrand_var_1 = tf.Variable(rand_t)\nrand_var_2 = tf.Variable(rand_t)\n\n...then tf.initialize_all_variables() will have the desired effect:\n\npythonCopy# Op 1\nz1 = tf.add(rand_var_1, rand_var_2)\n\n# Op 2\nz2 = tf.add(rand_var_1, rand_var_2)\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)        # Random numbers generated here and cached.\n    z1_op = sess.run(z1)  # Reuses cached values for rand_var_1, rand_var_2.\n    z2_op = sess.run(z2)  # Reuses cached values for rand_var_1, rand_var_2.\n    print(z1_op, z2_op)   # Will print two identical vectors.",
    "mlApiName": "tf.Variable,tf.initialize_all_variables,tf.random_uniform",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "Let's assume I have an array in TensorFlow:\n\npythonCopy[ 0.12300211,  0.51767069,  0.13886075,  0.55363625],\n[ 0.47279349,  0.50432992,  0.48080254,  0.51576483],\n[ 0.84347934,  0.44505221,  0.88839239,  0.48857492],\n[ 0.93650454,  0.43652734,  0.96464157,  0.47236174], ..\n\nI would like to sort this array by the third column. How do I do this? I am able to sort each column individually using tf.nn.top_k(), which gives me the sorted values and the respective indices. I could use the indices of this third column to reorder the others, but I cannot find a reordering Op.\n\nAssuming I want to keep things in-graph (no Python shenanigans):\n\nHow do I sort (the above array) in TensorFlow?\nHow do I re-order in TensorFlow when I have indices for re-ordering?",
    "answer": "The following works :\n\npythonCopya = tf.constant(...) # the array\nreordered = tf.gather(a, tf.nn.top_k(a[:, 2], k=4).indices)",
    "mlApiName": "tf.Session.run",
    "embedding": [],
    "label": {
      "level1": "SAM ",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm playing around with tensorflow and ran into a problem with the following code:\n\npythonCopydef _init_parameters(self, input_data, labels):\n\n    # the input shape is (batch_size, input_size)\n    input_size = tf.shape(input_data)[1]\n\n    # labels in one-hot format have shape (batch_size, num_classes)\n    num_classes = tf.shape(labels)[1]\n\n    stddev = 1.0 / tf.cast(input_size, tf.float32)\n\n    w_shape = tf.pack([input_size, num_classes], 'w-shape')\n    normal_dist = tf.truncated_normal(w_shape, stddev=stddev, name='normaldist')\n    self.w = tf.Variable(normal_dist, name='weights')\n\n(I'm using tf.pack as suggested in this question, since I was getting the same error)\n\nWhen I run it (from a larger script that invokes this one), I get this error:\n\npythonCopyValueError: initial_value must have a shape specified: Tensor(\"normaldist:0\", shape=TensorShape([Dimension(None), Dimension(None)]), dtype=float32)\n\nI tried to replicate the process in the interactive shell. Indeed, the dimensions of normal_dist are unspecified, although the supplied values do exist:\n\npythonCopyIn [70]: input_size.eval()\nOut[70]: 4\n\nIn [71]: num_classes.eval()\nOut[71]: 3\n\nIn [72]: w_shape.eval()\nOut[72]: array([4, 3], dtype=int32)\n\nIn [73]: normal_dist.eval()\nOut[73]: \narray([[-0.27035281, -0.223277  ,  0.14694688],\n       [-0.16527176,  0.02180306,  0.00807841],\n       [ 0.22624688,  0.36425814, -0.03099642],\n       [ 0.25575709, -0.02765726, -0.26169327]], dtype=float32)\n\nIn [78]: normal_dist.get_shape()\nOut[78]: TensorShape([Dimension(None), Dimension(None)])\n\nThis is weird. Tensorflow generates the vector but can't say its shape. Am I doing something wrong?",
    "answer": "As Ishamael says, all tensors have a static shape, which is known at graph construction time and accessible using Tensor.get_shape(); and a dynamic shape, which is only known at runtime and is accessible by fetching the value of the tensor, or passing it to an operator like tf.shape. In many cases, the static and dynamic shapes are the same, but they can be different - the static shape can be partially defined - in order allow the dynamic shape to vary from one step to the next.\n\nIn your code normal_dist has a partially-defined static shape, because w_shape is a computed value. (TensorFlow sometimes attempts to evaluate\nthese computed values at graph construction time, but it gets stuck at tf.pack.) It infers the shape TensorShape([Dimension(None), Dimension(None)]), which means \"a matrix with an unknown number of rows and columns,\" because it knowns that w_shape is a vector of length 2, so the resulting normal_dist must be 2-dimensional.\n\nYou have two options to deal with this. You can set the static shape as Ishamael suggests, but this requires you to know the shape at graph construction time. For example, the following may work:\n\npythonCopynormal_dist.set_shape([input_data.get_shape()[1], labels.get_shape()[1]])\n\nAlternatively, you can pass validate_shape=False to the tf.Variable constructor. This allows you to create a variable with a partially-defined shape, but it limits the amount of static shape information that can be inferred later on in the graph.",
    "mlApiName": "tf.Tensor.set_shape,tf.Variable",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am looking at the TensorFlow \"MNIST For ML Beginners\" tutorial, and I want to print out the training loss after every training step.\n\nMy training loop currently looks like this:\n\npythonCopyfor i in range(100):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\nNow, train_step is defined as:\n\npythonCopytrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n\nWhere cross_entropy is the loss which I want to print out:\n\npythonCopycross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n\nOne way to print this would be to explicitly compute cross_entropy in the training loop:\n\npythonCopyfor i in range(100):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n    print 'loss = ' + str(cross_entropy)\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\nI now have two questions regarding this:\n\nGiven that cross_entropy is already computed during sess.run(train_step, ...), it seems inefficient to compute it twice, requiring twice the number of forward passes of all the training data. Is there a way to access the value of cross_entropy when it was computed during sess.run(train_step, ...)?\nHow do I even print a tf.Variable? Using str(cross_entropy) gives me an error...\n\nThank you!",
    "answer": "You can fetch the value of cross_entropy by adding it to the list of arguments to sess.run(...). For example, your for-loop could be rewritten as follows:\n\npythonCopyfor i in range(100):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n    _, loss_val = sess.run([train_step, cross_entropy],\n                           feed_dict={x: batch_xs, y_: batch_ys})\n    print 'loss = ' + loss_val\n\nThe same approach can be used to print the current value of a variable. Let's say, in addition to the value of cross_entropy, you wanted to print the value of a tf.Variable called W, you could do the following:\n\npythonCopyfor i in range(100):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n    _, loss_val, W_val = sess.run([train_step, cross_entropy, W],\n                                  feed_dict={x: batch_xs, y_: batch_ys})\n    print 'loss = %s' % loss_val\n    print 'W = %s' % W_val",
    "mlApiName": "tf.Session.run",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm trying to run the CIFAR10 tutorial with the training code on one gpu and the eval code on the other. I know for sure I have two gpus on my computer, and I can test this by running the simple examples here: https://www.tensorflow.org/how_tos/using_gpu/index.html\n\nHowever, using a with device('/gpu:0') does not work for most variables in the CIFAR example. I tried a whole lot of combinations of different variables on gpu vs. cpu, or all the variables on one or the other. Always the same error for some variable, something like this:\n\npythonCopyCannot assign a device to node 'shuffle_batch/random_shuffle_queue': Could not satisfy explicit device specification '/gpu:0'\n\nIs this possibly a bug in Tensor Flow or am I missing something?",
    "answer": "Could not satisfy explicit device specification means you do not have the corresponding device. Do you actually have a CUDA-enabled GPU on your machine?\n\nUPDATE: As it turned out in the discussion below, this error is also raised if the particular operation (in this case, RandomShuffleQueue) cannot be executed on the GPU, because it only has a CPU implementation.\n\nIf you are fine with TensorFlow choosing a device for you (particularly, falling back to CPU when no GPU implementation is available), consider setting allow_soft_placement in your configuration, as per this article:\n\npythonCopysess = tf.Session(config=tf.ConfigProto(\n    allow_soft_placement=True, log_device_placement=True))",
    "mlApiName": "tf.ConfigProto",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I have a setup where I need to initialize an LSTM after the main initialization which uses tf.initialize_all_variables(). I.e. I want to call tf.initialize_variables([var_list]) \n\nIs there way to collect all the internal trainable variables for both:\n\nrnn_cell.BasicLSTM\nrnn_cell.MultiRNNCell\n\nso that I can initialize JUST these parameters?\n\nThe main reason I want this is because I do not want to re-initialize some trained values from earlier.",
    "answer": "The easiest way to solve your problem is to use variable scope. The names of the variables within a scope will be prefixed with its name. Here is a short snippet:\n\npythonCopycell = rnn_cell.BasicLSTMCell(num_nodes)\n\nwith tf.variable_scope(\"LSTM\") as vs:\n  # Execute the LSTM cell here in any way, for example:\n  for i in range(num_steps):\n    output[i], state = cell(input_data[i], state)\n\n  # Retrieve just the LSTM variables.\n  lstm_variables = [v for v in tf.all_variables()\n                    if v.name.startswith(vs.name)]\n\n# [..]\n# Initialize the LSTM variables.\ntf.initialize_variables(lstm_variables)\n\nIt would work the same way with MultiRNNCell.\n\nEDIT: changed tf.trainable_variables to tf.all_variables()",
    "mlApiName": "tf.all_variables,tf.initialize_variables,tf.variable_scope",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am trying to read some image input for an image classification problem with TensorFlow.\n\nOf course, I am doing this with tf.image.decode_jpeg(...). My images have variable size and hence I am not able to specify a fixed shape for the image tensor.\n\nBut I need to scale the images depending on their actual size. Specifically, I want to scale the shorter side to a fixed value and the longer side in a way that the aspect ratio is preserved.\n\nI can get the actual shape of a certain image by shape = tf.shape(image). I am also able to do the computation for the new longer edge like \n\npythonCopyshape = tf.shape(image)\nheight = shape[0]\nwidth = shape[1]\nnew_shorter_edge = 400\nif height <= width:\n    new_height = new_shorter_edge\n    new_width = ((width / height) * new_shorter_edge)\nelse:\n    new_width = new_shorter_edge\n    new_height = ((height / width) * new_shorter_edge)\n\nMy problem now is that I cannot pass new_height and new_width to tf.image.resize_images(...) because one of them is a tensor and resize_images expects integers as height and width inputs.\n\nIs there a way to \"pull out\" the integer of the tensor or is there any other way to do my task with TensorFlow?\n\nThanks in advance.\n\nEdit\n\nSince I also had some other issues with tf.image.resize_images, here's the code that worked for me:\n\npythonCopyshape = tf.shape(image)\nheight = shape[0]\nwidth = shape[1]\nnew_shorter_edge = tf.constant(400, dtype=tf.int32)\n\nheight_smaller_than_width = tf.less_equal(height, width)\nnew_height_and_width = tf.cond(\n    height_smaller_than_width,\n    lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n    lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n)\n\nimage = tf.expand_dims(image, 0)\nimage = tf.image.resize_bilinear(image, tf.pack(new_height_and_width))\nimage = tf.squeeze(image, [0])",
    "answer": "The way to do this is to use the (currently experimental, but available in the next release) tf.cond()* operator. This operator is able to test a value computed at runtime, and execute one of two branches based on that value.\n\npythonCopyshape = tf.shape(image)\nheight = shape[0]\nwidth = shape[1]\nnew_shorter_edge = 400\nheight_smaller_than_width = tf.less_equal(height, width)\n\nnew_shorter_edge = tf.constant(400)\nnew_height, new_width = tf.cond(\n    height_smaller_than_width,\n    lambda: new_shorter_edge, (width / height) * new_shorter_edge,\n    lambda: new_shorter_edge, (height / width) * new_shorter_edge)\n\nNow you have Tensor values for new_height and new_width that will take the appropriate value at runtime.\n\n* To access the operator in the current released version, you'll need to import the following:\n\npythonCopyfrom tensorflow.python.ops import control_flow_ops\n\n...and then use control_flow_ops.cond() instead of tf.cond().",
    "mlApiName": "tf.image.resize_bilinear,tf.python.ops.control_flow_ops.cond",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Data Preprocessing",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm having trouble recovering a tensor by name, I don't even know if it's possible.\n\nI have a function that creates my graph:\n\npythonCopydef create_structure(tf, x, input_size,dropout):    \n with tf.variable_scope(\"scale_1\") as scope:\n  W_S1_conv1 = deep_dive.weight_variable_scaling([7,7,3,64], name='W_S1_conv1')\n  b_S1_conv1 = deep_dive.bias_variable([64])\n  S1_conv1 = tf.nn.relu(deep_dive.conv2d(x_image, W_S1_conv1,strides=[1, 2, 2, 1], padding='SAME') + b_S1_conv1, name=\"Scale1_first_relu\")\n.\n.\n.\nreturn S3_conv1,regularizer\n\nI want to access the variable S1_conv1 outside this function. I tried:\n\npythonCopywith tf.variable_scope('scale_1') as scope_conv: \n tf.get_variable_scope().reuse_variables()\n ft=tf.get_variable('Scale1_first_relu')\n\nBut that is giving me an error:\n\nValueError: Under-sharing: Variable scale_1/Scale1_first_relu does not exist, disallowed. Did you mean to set reuse=None in VarScope?\n\nBut this works:\n\npythonCopywith tf.variable_scope('scale_1') as scope_conv: \n tf.get_variable_scope().reuse_variables()\n ft=tf.get_variable('W_S1_conv1')\n\nI can get around this with\n\npythonCopyreturn S3_conv1,regularizer, S1_conv1\n\nbut I don't want to do that.\n\nI think my problem is that S1_conv1 is not really a variable, it's just a tensor. Is there a way to do what I want?",
    "answer": "There is a function tf.Graph.get_tensor_by_name(). For instance:\n\npythonCopyimport tensorflow as tf\n\nc = tf.constant([[1.0, 2.0], [3.0, 4.0]])\nd = tf.constant([[1.0, 1.0], [0.0, 1.0]])\ne = tf.matmul(c, d, name='example')\n\nwith tf.Session() as sess:\n    test =  sess.run(e)\n    print e.name #example:0\n    test = tf.get_default_graph().get_tensor_by_name(\"example:0\")\n    print test #Tensor(\"example:0\", shape=(2, 2), dtype=float32)",
    "mlApiName": "tf.train.AdamOptimizer.apply_gradients,tf.train.AdamOptimizer.compute_gradients",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I've found that indexing still is an open issue in tensorflow (#206), so I'm wondering what I could use as a workaround at the moment. I want to index/slice a row/column of a matrix based on a variable that changes for every training example.\n\nWhat I've tried so far:\n\nSlicing based on placeholder (doesn't work)\n\nThe following (working) code slices based on a fixed number.\n\npythonCopyimport tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(\"float\")\ny = tf.slice(x,[0],[1])\n\n#initialize\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n\n#run\nresult = sess.run(y, feed_dict={x:[1,2,3,4,5]})\nprint(result)\n\nHowever, it seems that I can't simply replace one of these fixed numbers with a tf.placeholder. The following code gives me the error \"TypeError: List of Tensors when single Tensor expected.\"\n\npythonCopyimport tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(\"float\")\ni = tf.placeholder(\"int32\")\ny = tf.slice(x,[i],[1])\n\n#initialize\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n\n#run\nresult = sess.run(y, feed_dict={x:[1,2,3,4,5],i:0})\nprint(result)\n\nThis sounds like the brackets around [i] are too much, but removing them  doesn't help either. How to use a placeholder/variable as index?\n\nSlicing based on python variable (doesn't backprop/update properly)\n\nI've also tried using a normal python variable as index. This does not lead to an error, but the network doesn't learn anything while training. I suppose because the changing variable is not properly registered, the graph is malformed and updates don't work?\n\nSlicing via one-hot vector + multiplication (works, but is slow)\n\nOne workaround I found is using a one-hot vector. Making a one-hot vector in numpy, passing this using a placeholder, then doing the slicing via matrix multiplication. This works, but is quite slow.\n\nAny ideas how to efficiently slice/index based on a variable?",
    "answer": "Slicing based on a placeholder should work just fine. It looks like you are running into a type error, due to some subtle issues of shapes and types. Where you have the following:\n\npythonCopyx = tf.placeholder(\"float\")\ni = tf.placeholder(\"int32\")\ny = tf.slice(x,[i],[1])\n\n...you should instead have:\n\npythonCopyx = tf.placeholder(\"float\")\ni = tf.placeholder(\"int32\")\ny = tf.slice(x,i,[1])\n\n...and then you should feed i as [0] in the call to sess.run().\n\nTo make this a little clearer, I would recommend rewriting the code as follows:\n\npythonCopyimport tensorflow as tf\nimport numpy as np\n\nx = tf.placeholder(tf.float32, shape=[None])  # 1-D tensor\ni = tf.placeholder(tf.int32, shape=[1])\ny = tf.slice(x, i, [1])\n\n#initialize\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n\n#run\nresult = sess.run(y, feed_dict={x: [1, 2, 3, 4, 5], i: [0]})\nprint(result)\n\nThe additional shape arguments to the tf.placeholder op help to ensure that the values you feed have the appropriate shapes, and also that TensorFlow will raise an error if the shapes are not correct.",
    "mlApiName": "tf.slice",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "i'am still trying to run Tensorflow with own image data. \nI was able to create a .tfrecords file with the conevert_to() function from this example link\n\nNow i i'd like to train the network with code from that example link. \n\nBut it fails in the read_and_decode() function. My changes in that function are:\n\npythonCopylabel = tf.decode_raw(features['label'], tf.string) \n\nThe Error is:\n\npythonCopyTypeError: DataType string for attr 'out_type' not in list of allowed values: float32, float64, int32, uint8, int16, int8, int64\n\nSo how to 1) read and 2) use string labels for training in tensorflow.",
    "answer": "The convert_to_records.py script creates a .tfrecords file in which each record is an Example protocol buffer. That protocol buffer supports string features using the bytes_list kind.\n\nThe tf.decode_raw op is used to parse binary strings into image data; it is not designed to parse string (textual) labels. Assuming that features['label'] is a tf.string tensor, you can use the tf.string_to_number op to convert it to a number. There is limited other support for string processing inside your TensorFlow program, so if you need to perform some more complicated function to convert the string label to an integer, you should perform this conversion in Python in the modified version of convert_to_tensor.py.",
    "mlApiName": "tf.io.decode_raw",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "BIT",
      "leafContractCategory": "BIT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I understand that tf.where will return the locations of True values, so that I could use the result's shape[0] to get the number of Trues. \n\nHowever, when I try and use this, the dimension is unknown (which makes sense as it needs to be computed at runtime). So my question is, how can I access a dimension and use it in an operation like a sum?\n\nFor example:\n\npythonCopymyOtherTensor = tf.constant([[True, True], [False, True]])\nmyTensor = tf.where(myOtherTensor)\nmyTensor.get_shape() #=> [None, 2]\nsum = 0\nsum += myTensor.get_shape().as_list()[0] # Well defined at runtime but considered None until then.",
    "answer": "You can cast the values to floats and compute the sum on them:\ntf.reduce_sum(tf.cast(myOtherTensor, tf.float32))\n\nDepending on your actual use case you can also compute sums per row/column if you specify the reduce dimensions of the call.",
    "mlApiName": "tf.math.reduce_sum",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I have set up a CNN in Tensorflow where I read my data with a TFRecordReader. It works well but I would like to do some more preprocessing and data augmentation than offered by the tf.image functions. I would specifically like to do some randomized scaling.\n\nIs it possible to process a Tensorflow tensor in Numpy? Or do I need to drop the TFRecordReader and rather do all my preprocessing in Numpy and feed data using the feed_dict? I suspect that the feed_dict method is slow when training on images, but I might be wrong?",
    "answer": "If you could create a custom I/O pipeline that fetches intermediate results back from TensorFlow using one or more threads, applies arbitrary Python logic, and then feeds them into a queue for subsequent processing. The resulting program would be somewhat more complicated, but I suggest you look at the threading and queues HOWTO for information on how to get started.\n\nThere is an experimental feature that might make this easier, if you install from source.\n\nIf you have already built a preprocessing pipeline using TensorFlow ops, the easiest way to add some custom Python code is to use the tf.py_func() operator, which takes a list of Tensor objects, and a Python function that maps one or more NumPy arrays to one or more NumPy arrays.\n\nFor example, let's say you have a pipeline like this:\n\npythonCopyreader = tf.TFRecordReader(...)\nimage_t = tf.image.decode_png(tf.parse_single_example(reader.read(), ...))\n\n...you could use tf.py_func() to apply some custom NumPy processing as follows:\n\npythonCopyfrom scipy import ndimage\ndef preprocess(array):\n  # `array` is a NumPy array containing.\n  return ndimage.rotate(array, 45)\n\nimage_t = tf.py_func(preprocess, [image_t], [tf.float32])",
    "mlApiName": "tf.TFRecordReader,tf.io.decode_png,tf.py_func",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Data Preprocessing",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "The text data is organized as vector with 20,000 elements, like [2, 1, 0, 0, 5, ...., 0]. \ni-th element indicates the frequency of the i-th word in a text. \n\nThe ground truth label data is also represented as vector with 4,000 elements, like [0, 0, 1, 0, 1, ...., 0]. \ni-th element indicates whether the i-th label is a positive label for a text. \nThe number of labels for a text differs depending on texts. \n\nI have a code for single-label text classification. \n\nHow can I edit the following code for multilabel text classification?\n\nEspecially, I would like to know following points. \n\nHow to compute accuracy using TensorFlow. \nHow to set a threshold which judges whether a label is positive or negative. For instance, if the output is [0.80, 0.43, 0.21, 0.01, 0.32] and the ground truth is [1, 1, 0, 0, 1], the labels with scores over 0.25 should be judged as positive. \n\nThank you. \n\npythonCopyimport tensorflow as tf\n\n# hidden Layer\nclass HiddenLayer(object):\n    def __init__(self, input, n_in, n_out):\n        self.input = input\n\n        w_h = tf.Variable(tf.random_normal([n_in, n_out],mean = 0.0,stddev = 0.05))\n        b_h = tf.Variable(tf.zeros([n_out]))\n\n        self.w = w_h\n        self.b = b_h\n        self.params = [self.w, self.b]\n\n    def output(self):\n        linarg = tf.matmul(self.input, self.w) + self.b\n        self.output = tf.nn.relu(linarg)\n\n        return self.output\n\n# output Layer\nclass OutputLayer(object):\n    def __init__(self, input, n_in, n_out):\n        self.input = input\n\n        w_o = tf.Variable(tf.random_normal([n_in, n_out], mean = 0.0, stddev = 0.05))\n        b_o = tf.Variable(tf.zeros([n_out]))\n\n        self.w = w_o\n        self.b = b_o\n        self.params = [self.w, self.b]\n\n    def output(self):\n        linarg = tf.matmul(self.input, self.w) + self.b\n        self.output = tf.nn.relu(linarg)\n\n        return self.output\n\n# model\ndef model():\n    h_layer = HiddenLayer(input = x, n_in = 20000, n_out = 1000)\n    o_layer = OutputLayer(input = h_layer.output(), n_in = 1000, n_out = 4000)\n\n    # loss function\n    out = o_layer.output()\n    cross_entropy = -tf.reduce_sum(y_*tf.log(out + 1e-9), name='xentropy')    \n\n    # regularization\n    l2 = (tf.nn.l2_loss(h_layer.w) + tf.nn.l2_loss(o_layer.w))\n    lambda_2 = 0.01\n\n    # compute loss\n    loss = cross_entropy + lambda_2 * l2\n\n    # compute accuracy for single label classification task\n    correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n\n    return loss, accuracy",
    "answer": "Change relu to sigmoid of output layer.\nModify cross entropy loss to explicit mathematical formula of sigmoid cross entropy loss (explicit loss was working in my case/version of tensorflow )\n\npythonCopyimport tensorflow as tf\n\n# hidden Layer\nclass HiddenLayer(object):\n    def __init__(self, input, n_in, n_out):\n        self.input = input\n\n        w_h = tf.Variable(tf.random_normal([n_in, n_out],mean = 0.0,stddev = 0.05))\n        b_h = tf.Variable(tf.zeros([n_out]))\n\n        self.w = w_h\n        self.b = b_h\n        self.params = [self.w, self.b]\n\n    def output(self):\n        linarg = tf.matmul(self.input, self.w) + self.b\n        self.output = tf.nn.relu(linarg)\n\n        return self.output\n\n# output Layer\nclass OutputLayer(object):\n    def __init__(self, input, n_in, n_out):\n        self.input = input\n\n        w_o = tf.Variable(tf.random_normal([n_in, n_out], mean = 0.0, stddev = 0.05))\n        b_o = tf.Variable(tf.zeros([n_out]))\n\n        self.w = w_o\n        self.b = b_o\n        self.params = [self.w, self.b]\n\n    def output(self):\n        linarg = tf.matmul(self.input, self.w) + self.b\n        #changed relu to sigmoid\n        self.output = tf.nn.sigmoid(linarg)\n\n        return self.output\n\n# model\ndef model():\n    h_layer = HiddenLayer(input = x, n_in = 20000, n_out = 1000)\n    o_layer = OutputLayer(input = h_layer.output(), n_in = 1000, n_out = 4000)\n\n    # loss function\n    out = o_layer.output()\n    # modified cross entropy to explicit mathematical formula of sigmoid cross entropy loss\n    cross_entropy = -tf.reduce_sum( (  (y_*tf.log(out + 1e-9)) + ((1-y_) * tf.log(1 - out + 1e-9)) )  , name='xentropy' )    \n\n    # regularization\n    l2 = (tf.nn.l2_loss(h_layer.w) + tf.nn.l2_loss(o_layer.w))\n    lambda_2 = 0.01\n\n    # compute loss\n    loss = cross_entropy + lambda_2 * l2\n\n    # compute accuracy for single label classification task\n    correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n\n    return loss, accuracy",
    "mlApiName": "tf.linalg.matmul,tf.nn.relu",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm trying to apply the expert portion of the tutorial to my own data but I keep running into dimension errors. Here's the code leading up to the error.\n\npythonCopydef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')\n\nW_conv1 = weight_variable([1, 8, 1, 4])\nb_conv1 = bias_variable([4])\n\nx_image = tf.reshape(tf_in, [-1,2,8,1])\n\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\n\nAnd then when I try to run this command:\n\npythonCopyW_conv2 = weight_variable([1, 4, 4, 8])\nb_conv2 = bias_variable([8])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)\n\nI get the following errors:\n\npythonCopyValueError                                Traceback (most recent call last)\n in ()\n      3 \n      4 h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n----> 5 h_pool2 = max_pool_2x2(h_conv2)\n\nValueError: ('filter must not be larger than the input: ', 'Filter: [', Dimension(2), 'x', Dimension(2), '] ', 'Input: [', Dimension(1), 'x', Dimension(4), '] ')\n\nJust for some background information, the data that I'm dealing with is a CSV file where each row contains 10 features and 1 empty column that can be a 1 or a 0. What I'm trying to get is a probability in the empty column that the column will equal a 1.",
    "answer": "You have to shape the input so it is compatible with both the training tensor and the output. If you input is length 1, your output should be length 1 (length is substituted for dimension).\n\nWhen you're dealing with-\n\npythonCopydef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 1, 1, 1],\n                    strides=[1, 1, 1, 1], padding='SAME')\n\nNotice how I changed the strides and the ksize to [1, 1, 1, 1]. This will match an output to a 1 dimensional input and prevent errors down the road.\n\nWhen you're defining your weight variable (see code below)-\n\npythonCopydef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\nyou're going to have to make the first 2 numbers conform to the feature tensor that you are using to train your model, the last two numbers will be the dimension of the predicted output (same as the dimension of the input).\n\npythonCopyW_conv1 = weight_variable([1, 10, 1, 1])\nb_conv1 = bias_variable([1])\n\nNotice the [1, 10, in the beginning which signifies that the feature tensor is going to be a 1x10 feature tensor; the last two numbers 1, 1] correspond to the dimensions of the input and output tensors/predictors.\n\nWhen you reshape your x_foo tensor (I call it x_ [x prime]), you, for whatever reason, have to define it like so-\n\npythonCopyx_ = tf.reshape(x, [-1,1,10,1])\n\nNotice the 1 and 10 in the middle- ...1,10,.... Once again, these numbers correspond to the dimension of your feature tensor.\n\nFor every bias variable, you choose the final number of the previously defined variable. For example, if W_conv1 = weight_variable([1, 10, 1, 1]) appears like so, you take the final number and put that into your bias variable so it can match the dimensions of the input. This is done like so- b_conv1 = bias_variable([1]).\n\nIf you need any more explanation please comment below.",
    "mlApiName": "tf.nn.conv2d,tf.nn.max_pool",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I was trying to use an RNN (specifically, LSTM) for sequence prediction. However, I ran into an issue with variable sequence lengths. For example,\n\npythonCopysent_1 = \"I am flying to Dubain\"\nsent_2 = \"I was traveling from US to Dubai\"\n\nI am trying to predicting the next word after the current one with a simple RNN based on this Benchmark for building a PTB LSTM model.\n\nHowever, the num_steps parameter (used for unrolling to the previous hidden states), should remain the same in each Tensorflow's epoch. Basically, batching sentences is not possible as the sentences vary in length. \n\npythonCopy # inputs = [tf.squeeze(input_, [1])\n #           for input_ in tf.split(1, num_steps, inputs)]\n # outputs, states = rnn.rnn(cell, inputs, initial_state=self._initial_state)\n\nHere, num_steps need to be changed in my case for every sentence. I have tried several hacks, but nothing seems working.",
    "answer": "You can use the ideas of bucketing and padding which are described in:  \n\nSequence-to-Sequence Models\n\nAlso, the rnn function which creates RNN network accepts parameter sequence_length.\n\nAs an example, you can create buckets of sentences of the same size, pad them with the necessary amount of zeros, or placeholders which stand for zero word and afterwards feed them along with seq_length = len(zero_words).\n\npythonCopyseq_length = tf.placeholder(tf.int32)\noutputs, states = rnn.rnn(cell, inputs, initial_state=initial_state, sequence_length=seq_length)\n\nsess = tf.Session()\nfeed = {\n    seq_length: 20,\n    #other feeds\n}\nsess.run(outputs, feed_dict=feed)\n\nTake a look at this reddit thread as well:  \n\nTensorflow basic RNN example with 'variable length' sequences",
    "mlApiName": "tf.Session.run,tf.models.rnn.rnn",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am trying to implement Adversarial NN, which requires to 'freeze' one or the other part of the graph during alternating training minibatches. I.e. there two sub-networks: G and D.\n\npythonCopyG( Z ) ->  Xz\nD( X ) ->  Y\n\nwhere loss function of G depends on D[G(Z)], D[X].\n\nFirst I need to train parameters in D with all G parameters fixed, and then parameters in G with parameters in D fixed. Loss function in first case will be negative loss function in the second case and the update will have to apply to the parameters of whether first or second subnetwork.\n\nI saw that tensorflow has tf.stop_gradient function. For purpose of training the D (downstream) subnetwork I can use this function to block the gradient flow to \n\npythonCopy Z -> [ G ] -> tf.stop_gradient(Xz) -> [ D ] -> Y\n\nThe tf.stop_gradient is very succinctly annotated with no in-line example (and example seq2seq.py is too long and not that easy to read), but looks like it must be called during the graph creation. Does it imply that if I want to block/unblock gradient flow in alternating batches, I need to re-create and re-initialize the graph model? \n\nAlso it seems that one cannot block the gradient flowing through the G (upstream) network by means of tf.stop_gradient, right?\n\nAs an alternative I saw that one can pass the list of variables to the optimizer call as opt_op = opt.minimize(cost, ), which would be an easy solution if one could get all variables in the scopes of each subnetwork. Can one get a  for a tf.scope?",
    "answer": "The easiest way to achieve this, as you mention in your question, is to create two optimizer operations using separate calls to opt.minimize(cost, ...). By default, the optimizer will use all of the variables in tf.trainable_variables(). If you want to filter the variables to a particular scope, you can use the optional scope argument to tf.get_collection() as follows:\n\npythonCopyoptimizer = tf.train.AdagradOptimzer(0.01)\n\nfirst_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n                                     \"scope/prefix/for/first/vars\")\nfirst_train_op = optimizer.minimize(cost, var_list=first_train_vars)\n\nsecond_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n                                      \"scope/prefix/for/second/vars\")                     \nsecond_train_op = optimizer.minimize(cost, var_list=second_train_vars)",
    "mlApiName": "tf.get_collection,tf.train.AdagradOptimizer.minimize",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "This question already has answers here:\n                                \n                            \n                    \n                \n            \n                    \n                        Reproducible results in Tensorflow with tf.set_random_seed\n                            \n                                (9 answers)\n                            \n                    \n                Closed 6 years ago.\n        \n\n    \n\nCalling tf.set_random_seed(SEED) has no effect that I can tell...\n\nFor example, running the code below several times inside an IPython notebook produces different output each time:\n\npythonCopyimport tensorflow as tf\ntf.set_random_seed(42)\nsess = tf.InteractiveSession()\na = tf.constant([1, 2, 3, 4, 5])\ntf.initialize_all_variables().run()\na_shuf = tf.random_shuffle(a)\nprint(a.eval())\nprint(a_shuf.eval())\nsess.close()\n\nIf I set the seed explicitly: a_shuf = tf.random_shuffle(a, seed=42), the output is the same after each run. But why do I need to set the seed if I already call tf.set_random_seed(42)?\n\nThe equivalent code using numpy just works:\n\npythonCopyimport numpy as np\nnp.random.seed(42)\na = [1,2,3,4,5]\nnp.random.shuffle(a)\nprint(a)",
    "answer": "That only sets the graph-level random seed. If you execute this snippet several times in a row, the graph will change, and two shuffle statements will get different operation-level seeds. The details are described in the doc string for set_random_seed\n\nTo get deterministic a_shuf you can either\n\nCall tf.reset_default_graph() between invocations or\nSet operation-level seed for shuffle: a_shuf = tf.random_shuffle(a, seed=42)",
    "mlApiName": "tf.Session.run,tf.initialize_all_variables",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I found in many available neural network code implemented using TensorFlow that regularization terms are often implemented by manually adding an additional term to loss value.\n\nMy questions are:\n\nIs there a more elegant or recommended way of regularization than doing it manually?\nI also find that get_variable has an argument regularizer. How should it be used? According to my observation, if we pass a regularizer to it (such as tf.contrib.layers.l2_regularizer, a tensor representing regularized term will be computed and added to a graph collection named tf.GraphKeys.REGULARIZATOIN_LOSSES. Will that collection be automatically used by TensorFlow (e.g. used by optimizers when training)? Or is it expected that I should use that collection by myself?",
    "answer": "As you say in the second point, using the regularizer argument is the recommended way. You can use it in get_variable, or set it once in your variable_scope and have all your variables regularized.\nThe losses are collected in the graph, and you need to manually add them to your cost function like this.\npythonCopy  reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n  reg_constant = 0.01  # Choose an appropriate one.\n  loss = my_normal_loss + reg_constant * sum(reg_losses)",
    "mlApiName": "tf.Graph,tf.Graph.get_default_graph,tf.Graph.get_default_graph.get_collection,tf.Graph.get_default_graph.get_operations,tf.Graph.set_default",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "MOB",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "There are many methods in TensorFlow that requires specifying a shape, for example truncated_normal:\n\npythonCopytf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n\nI have a placeholder for the input of shape [None, 784], where the first dimension is None because the batch size can vary. I could use a fixed batch size but it still would be different from the test/validation set size.\n\nI cannot feed this placeholder to tf.truncated_normal because it requires a fully specified tensor shape. What is a simple way to having tf.truncated_normal accept different tensor shapes?",
    "answer": "You just need to feed it in as a single example but in the batched shape. So that means adding an extra dimension to the shape e.g.\n\npythonCopybatch_size = 32 # set this to the actual size of your batch\ntf.truncated_normal((batch_size, 784), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n\nThis way it will \"fit\" into the placeholder.\n\nIf you expect batch_size to change you can also use:\n\npythonCopytf.truncated_normal(tf.shape(input_tensor), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n\nWhere input_tensor could be a placeholder or just whatever tensor is going to have this noise added to it.",
    "mlApiName": "tf.random.truncated_normal",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am trying to use tensorflow for transfer learning. I downloaded the pre-trained model inception3 from the tutorial. In the code, for prediction: \n\npythonCopyprediction = sess.run(softmax_tensor,{'DecodeJpeg/contents:0'}:image_data})\n\nIs there a way to feed the png image. I tried changing DecodeJpeg to DecodePng but it did not work. Beside, what should I change if I want to feed decoded image file like a numpy array or a batch of arrays?\n\nThanks!!",
    "answer": "The shipped InceptionV3 graph used in classify_image.py only supports JPEG images out-of-the-box. There are two ways you could use this graph with PNG images:\n\nConvert the PNG image to a height x width x 3 (channels) Numpy array, for example using PIL, then feed the 'DecodeJpeg:0' tensor:\n\npythonCopyimport numpy as np\nfrom PIL import Image\n# ...\n\nimage = Image.open(\"example.png\")\nimage_array = np.array(image)[:, :, 0:3]  # Select RGB channels only.\n\nprediction = sess.run(softmax_tensor, {'DecodeJpeg:0': image_array})\n\nPerhaps confusingly, 'DecodeJpeg:0' is the output of the DecodeJpeg op, so by feeding this tensor, you are able to feed raw image data.\nAdd a tf.image.decode_png() op to the imported graph. Simply switching the name of the fed tensor from 'DecodeJpeg/contents:0' to 'DecodePng/contents:0' does not work because there is no 'DecodePng' op in the shipped graph. You can add such a node to the graph by using the input_map argument to tf.import_graph_def():\n\npythonCopypng_data = tf.placeholder(tf.string, shape=[])\ndecoded_png = tf.image.decode_png(png_data, channels=3)\n# ...\n\ngraph_def = ...\nsoftmax_tensor = tf.import_graph_def(\n    graph_def,\n    input_map={'DecodeJpeg:0': decoded_png},\n    return_elements=['softmax:0'])\n\nsess.run(softmax_tensor, {png_data: ...})",
    "mlApiName": "tf.Session.run,tf.import_graph_def,tf.io.decode_png",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I was wondering how to handle not labeled parts of an image in image segmentation using TensorFlow. For example, my input is an image of height * width * channels. The labels are too of the size height * width, with one label for every pixel.\n\nSome parts of the image are annotated, other parts are not. I would wish that those parts have no influence on the gradient computation whatsoever. Furthermore, I am not interested in the network predicting this void label.\n\nIs there a label or a function for this? At the moment I am using tf.nn.sparse_softmax_cross_entropy_with_logits.",
    "answer": "I'm not 100% familiar with TF. However, have you considered using the weights parameter of the loss?\n\nLooking at tf.loses.sparse_softmax_cross_entropy it has a parameter weights\n\n  weights: Coefficients for the loss. This must be scalar or of same rank as labels \n\nYou can set weightof  \"void\" pixels to zero, thus making the loss ignore them.\n\nYou can also remove the reduction from tf.nn.sparse_softmax_cross_entropy_with_logits and use tf.losses.compute_weighted_loss to perform the weighting.",
    "mlApiName": "tf.concat",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "BIT",
      "leafContractCategory": "BIT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "The question is, whether just changing the learning_rate argument in tf.train.AdamOptimizer actually results in any changes in behaviour: \nLet's say the code looks like this: \n\npythonCopymyLearnRate = 0.001\n...\noutput = tf.someDataFlowGraph\ntrainLoss = tf.losses.someLoss(output)\ntrainStep = tf.train.AdamOptimizer(learning_rate=myLearnRate).minimize(trainLoss)\nwith tf.Session() as session:\n    #first trainstep\n    session.run(trainStep, feed_dict = {input:someData, target:someTarget})\n    myLearnRate = myLearnRate * 0.1\n    #second trainstep\n    session.run(trainStep, feed_dict = {input:someData, target:someTarget})\n\nWould the decreased myLearnRate now be applied in the second trainStep? This is, is the creation of the node trainStep only evaluated once: \n\npythonCopytrainStep = tf.train.AdamOptimizer(learning_rate=myLearnRate).minimize(trainLoss)\n\nOr is it evaluated with every session.run(train_step)? How could I have checked in my AdamOptimizer in Tensorflow, whether it did change the Learnrate. \n\nDisclaimer 1: I'm aware manually changing the LearnRate is bad practice. \nDisclaimer 2: I'm aware there is a similar question, but it was solved with inputting a tensor as learnRate, which is updated in every trainStep (here). It makes me lean towards assuming it would only work with a tensor as input for the learning_rate in AdamOptimizer, but neither am I sure of that, nor can I understand the reasoning behind it.",
    "answer": "The short answer is that no, your new learning rate is not applied. TF builds the graph when you first run it, and changing something on the Python side will not translate to a change in the graph at run time. You can, however, feed a new learning rate into your graph pretty easily:\npythonCopy# Use a placeholder in the graph for your user-defined learning rate instead\nlearning_rate = tf.placeholder(tf.float32)\n# ...\ntrainStep = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(trainLoss)\napplied_rate = 0.001  # we will update this every training step\nwith tf.Session() as session:\n    #first trainstep, feeding our applied rate to the graph\n    session.run(trainStep, feed_dict = {input: someData,\n                                        target: someTarget,\n                                        learning_rate: applied_rate})\n    applied_rate *= 0.1  # update the rate we feed to the graph\n    #second trainstep\n    session.run(trainStep, feed_dict = {input: someData,\n                                        target: someTarget,\n                                        learning_rate: applied_rate})",
    "mlApiName": "tf.contrib.data.TFRecordDataset.padded_batch",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "BIT",
      "leafContractCategory": "BIT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Data Preprocessing",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am trying to understand the strides argument in tf.nn.avg_pool, tf.nn.max_pool, tf.nn.conv2d. \n\nThe documentation repeatedly says \n\n  strides: A list of ints that has length >= 4. The stride of the sliding window for each dimension of the input tensor.\n\nMy questions are:\n\nWhat do each of the 4+ integers represent?\nWhy must they have strides[0] = strides[3] = 1 for convnets?\nIn this example we see tf.reshape(_X,shape=[-1, 28, 28, 1]). Why -1?\n\nSadly the examples in the docs for reshape using -1 don't translate too well to this scenario.",
    "answer": "The pooling and convolutional ops slide a \"window\" across the input tensor.  Using tf.nn.conv2d as an example: If the input tensor has 4 dimensions:  [batch, height, width, channels], then the convolution operates on a 2D window on the height, width dimensions.\n\nstrides determines how much the window shifts by in each of the dimensions.  The typical use sets the first (the batch) and last (the depth) stride to 1.\n\nLet's use a very concrete example:  Running a 2-d convolution over a 32x32 greyscale input image.  I say greyscale because then the input image has depth=1, which helps keep it simple.  Let that image look like this:\n\npythonCopy00 01 02 03 04 ...\n10 11 12 13 14 ...\n20 21 22 23 24 ...\n30 31 32 33 34 ...\n...\n\nLet's run a 2x2 convolution window over a single example (batch size = 1).  We'll give the convolution an output channel depth of 8.\n\nThe input to the convolution has shape=[1, 32, 32, 1].\n\nIf you specify strides=[1,1,1,1] with padding=SAME, then the output of the filter will be [1, 32, 32, 8].\n\nThe filter will first create an output for:\n\npythonCopyF(00 01\n  10 11)\n\nAnd then for:\n\npythonCopyF(01 02\n  11 12)\n\nand so on.  Then it will move to the second row, calculating:\n\npythonCopyF(10, 11\n  20, 21)\n\nthen\n\npythonCopyF(11, 12\n  21, 22)\n\nIf you specify a stride of [1, 2, 2, 1] it won't do overlapping windows.  It will compute:\n\npythonCopyF(00, 01\n  10, 11)\n\nand then\n\npythonCopyF(02, 03\n  12, 13)\n\nThe stride operates similarly for the pooling operators.\n\nQuestion 2:  Why strides [1, x, y, 1] for convnets\n\nThe first 1 is the batch:  You don't usually want to skip over examples in your batch, or you shouldn't have included them in the first place. :)\n\nThe last 1 is the depth of the convolution:  You don't usually want to skip inputs, for the same reason.\n\nThe conv2d operator is more general, so you could create convolutions that slide the window along other dimensions, but that's not a typical use in convnets.  The typical use is to use them spatially.\n\nWhy reshape to -1  -1 is a placeholder that says \"adjust as necessary to match the size needed for the full tensor.\"  It's a way of making the code be independent of the input batch size, so that you can change your pipeline and not have to adjust the batch size everywhere in the code.",
    "mlApiName": "tf.nn.conv2d",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-2",
      "leafContractCategory": "IC-2",
      "rootCause": "Missing Input Value/Type Dependency",
      "effect": "Unknown",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "Considering the example code.\n\nI would like to know How to apply gradient clipping on this network on the RNN where there is a possibility of exploding gradients.\n\npythonCopytf.clip_by_value(t, clip_value_min, clip_value_max, name=None)\n\nThis is an example that could be used but where do I introduce this ?\nIn the def of RNN \n\npythonCopy    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n    _X = tf.split(0, n_steps, _X) # n_steps\ntf.clip_by_value(_X, -1, 1, name=None)\n\nBut this doesn't make sense as the tensor _X is the input and not the grad what is to be clipped? \n\nDo I have to define my own Optimizer for this or is there a simpler option?",
    "answer": "Gradient clipping needs to happen after computing the gradients, but before applying them to update the model's parameters. In your example, both of those things are handled by the AdamOptimizer.minimize() method.\nIn order to clip your gradients you'll need to explicitly compute, clip, and apply them as described in this section in TensorFlow's API documentation. Specifically you'll need to substitute the call to the minimize() method with something like the following:\npythonCopyoptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ngvs = optimizer.compute_gradients(cost)\ncapped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\ntrain_op = optimizer.apply_gradients(capped_gvs)",
    "mlApiName": "tf.linalg.matmul",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-2",
      "leafContractCategory": "IC-2",
      "rootCause": "Missing Input Value/Type Dependency",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I would like to build a toy LSTM model for regression. This nice tutorial is already too complicated for a beginner. \n\nGiven a sequence of length time_steps, predict the next value. Consider time_steps=3 and the sequences: \n\npythonCopyarray([\n   [[  1.],\n    [  2.],\n    [  3.]],\n\n   [[  2.],\n    [  3.],\n    [  4.]],\n    ...\n\nthe target values should be:\n\npythonCopyarray([  4.,   5., ...\n\nI define the following model:\n\npythonCopy# Network Parameters\ntime_steps = 3 \nnum_neurons= 64 #(arbitrary)\nn_features = 1\n\n# tf Graph input\nx = tf.placeholder(\"float\", [None, time_steps, n_features])\ny = tf.placeholder(\"float\", [None, 1])\n\n# Define weights\nweights = {\n   'out': tf.Variable(tf.random_normal([n_hidden, 1]))\n} \nbiases = {\n   'out': tf.Variable(tf.random_normal([1]))\n}\n\n#LSTM model\ndef lstm_model(X, weights, biases, learning_rate=0.01, optimizer='Adagrad'):\n\n  # Prepare data shape to match `rnn` function requirements\n  # Current data input shape: (batch_size, time_steps, n_features)\n  # Required shape: 'time_steps' tensors list of shape (batch_size, n_features)\n  # Permuting batch_size and time_steps\n  input dimension: Tensor(\"Placeholder_:0\", shape=(?, 3, 1), dtype=float32)\n\n  X = tf.transpose(X, [1, 0, 2])\n  transposed dimension: Tensor(\"transpose_41:0\", shape=(3, ?, 1), dtype=float32)\n\n  # Reshaping to (time_steps*batch_size, n_features)\n  X = tf.reshape(X, [-1, n_features])\n  reshaped dimension: Tensor(\"Reshape_:0\", shape=(?, 1), dtype=float32)\n\n  # Split to get a list of 'time_steps' tensors of shape (batch_size, n_features)\n  X = tf.split(0, time_steps, X)\n  splitted dimension: [, , ]\n\n  # LSTM cell\n  cell = tf.nn.rnn_cell.LSTMCell(num_neurons) #Or GRUCell(num_neurons)\n\n  output, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.float32)\n\n  output = tf.transpose(output, [1, 0, 2])\n  last = tf.gather(output, int(output.get_shape()[0]) - 1)\n\n  return tf.matmul(last, weights['out']) + biases['out']\n\nWe instantiating the LSTM model with pred = lstm_model(x, weights, biases) I get the following:\n\npythonCopy---> output, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.float32)\nValueError: Dimension must be 2 but is 3 for 'transpose_42' (op: 'Transpose') with input shapes: [?,1], [3]\n\n1) Do you know what the problem is?\n\n2) Will multiplying the LSTM output by the weights yield the regression?",
    "answer": "As discussed in the comments, the tf.nn.dynamic_rnn(cell, inputs, ...) function expects a list of three-dimensional tensors* as its inputs argument, where the dimensions are interpreted by default as batch_size x num_timesteps x num_features. (If you pass time_major=True, they are interpreted as num_timesteps x batch_size x num_features.) Therefore the preprocessing you've done in the original placeholder is unnecessary, and you can pass the oriding X value directly to tf.nn.dynamic_rnn().\n\n* Technically it can accept complicated nested structures in addition to lists, but the leaf elements must be three-dimensional tensors.**\n\n** Investigating this turned up a bug in the implementation of tf.nn.dynamic_rnn(). In principle, it should be sufficient for the inputs to have at least two dimensions, but the time_major=False path assumes that they have exactly three dimensions when it transposes the input into the time-major form, and it was the error message that this bug inadvertently causes that showed up in your program. We're working on getting that fixed.",
    "mlApiName": "tf.Session.run",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-2",
      "leafContractCategory": "IC-2",
      "rootCause": "Missing Input Value/Type Dependency",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Prediction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am following through the tutorial here:\nhttps://pythonprogramming.net/train-test-tensorflow-deep-learning-tutorial/\n\nI can get the Neural Network trained and print out the accuracy.\n\nHowever, I do not know how to use the Neural Network to make a prediction.\n\nHere is my attempt.  Specifically the issue is this line - I believe my issue is that I cannot get my input string into the format the model expects:\n\npythonCopyfeatures = get_features_for_input(\"This was the best store i've ever seen.\")\nresult = (sess.run(tf.argmax(prediction.eval(feed_dict={x:features}),1)))\n\nHere is a larger listing:\n\npythonCopydef train_neural_network(x):\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y)) \n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        for epoch in range(hm_epochs):\n            epoch_loss = 0\n            i = 0\n            while i < len(train_x):\n                start = i\n                end = i + batch_size\n\n                batch_x = np.array(train_x[start:end])\n                batch_y = np.array(train_y[start:end])\n\n                _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n\n                epoch_loss += c \n                i+=batch_size\n\n            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y,1))        \n        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n        print('Accuracy', accuracy.eval({x:test_x, y:test_y}))\n\n        # pos: [1,0] , argmax: 0\n        # neg: [0,1] , argmax: 1\n        features = get_features_for_input(\"This was the best store i've ever seen.\")\n        result = (sess.run(tf.argmax(prediction.eval(feed_dict={x:features}),1)))\n        if result[0] == 0:\n            print('Positive:',input_data)\n        elif result[0] == 1:\n            print('Negative:',input_data)\n\ndef get_features_for_input(input):\n    current_words = word_tokenize(input.lower())\n    current_words = [lemmatizer.lemmatize(i) for i in current_words]\n    features = np.zeros(len(lexicon))\n\n    for word in current_words:\n        if word.lower() in lexicon:\n            index_value = lexicon.index(word.lower())\n            # OR DO +=1, test both\n            features[index_value] += 1\n\n    features = np.array(list(features))\n\ntrain_neural_network(x)",
    "answer": "Following your comment above, it feels like your error ValueError: Cannot feed value of shape () is due to the fact that features is None, because your function get_features_for_input doesn't return anything.\n\nI added the return features line and gave features a correct shape of [1, len(lexicon)] to match the shape of the placeholder.\n\npythonCopydef get_features_for_input(input):\n    current_words = word_tokenize(input.lower())\n    current_words = [lemmatizer.lemmatize(i) for i in current_words]\n    features = np.zeros((1, len(lexicon)))\n\n    for word in current_words:\n        if word.lower() in lexicon:\n            index_value = lexicon.index(word.lower())\n            # OR DO +=1, test both\n            features[0, index_value] += 1\n\n    return features",
    "mlApiName": "tf.nn.dynamic_rnn",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-2",
      "leafContractCategory": "IC-2",
      "rootCause": "Missing Input Value/Type Dependency",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I have the following code portion for a convolutional neural network:\n\npythonCopyimport numpy as np\nimport matplotlib.pyplot as plt\nimport cifar_tools\nimport tensorflow as tf\n\ndata, labels = cifar_tools.read_data('C:\\\\Users\\\\abc\\\\Desktop\\\\temp')\n\nx = tf.placeholder(tf.float32, [None, 150 * 150])\ny = tf.placeholder(tf.float32, [None, 2])\n\nw1 = tf.Variable(tf.random_normal([5, 5, 1, 64]))\nb1 = tf.Variable(tf.random_normal([64]))\n\nw2 = tf.Variable(tf.random_normal([5, 5, 64, 64]))\nb2 = tf.Variable(tf.random_normal([64]))\n\nw3 = tf.Variable(tf.random_normal([6*6*64, 1024]))\nb3 = tf.Variable(tf.random_normal([1024]))\n\nw_out = tf.Variable(tf.random_normal([1024, 2]))\nb_out = tf.Variable(tf.random_normal([2]))\n\ndef conv_layer(x,w,b):\n    conv = tf.nn.conv2d(x,w,strides=[1,1,1,1], padding = 'SAME')\n    conv_with_b = tf.nn.bias_add(conv,b)\n    conv_out = tf.nn.relu(conv_with_b)\n    return conv_out\n\ndef maxpool_layer(conv,k=2):\n    return tf.nn.max_pool(conv, ksize=[1,k,k,1], strides=[1,k,k,1], padding='SAME')\n\ndef model():\n    x_reshaped = tf.reshape(x, shape=[-1,150,150,1])\n\n    conv_out1 = conv_layer(x_reshaped, w1, b1)\n    maxpool_out1 = maxpool_layer(conv_out1)\n    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n\n    conv_out2 = conv_layer(norm1, w2, b2)\n    maxpool_out2 = maxpool_layer(conv_out2)\n    norm2 = tf.nn.lrn(maxpool_out2, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n\n    maxpool_reshaped = tf.reshape(maxpool_out2, [-1,w3.get_shape().as_list()[0]])\n    local = tf.add(tf.matmul(maxpool_reshaped, w3), b3)\n    local_out = tf.nn.relu(local)\n\n    out = tf.add(tf.matmul(local_out, w_out), b_out)\n    return out\n\nmodel_op = model()\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model_op, y))\ntrain_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n\ncorrect_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n\nI'm reading 150x150 grayscale images, but couldn't understand the following error I'm having:\n\npythonCopyEPOCH 0\nTraceback (most recent call last):\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1021, in _do_call\n    return fn(*args)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1003, in _run_fn\n    status, run_metadata)\n  File \"C:\\Python35\\lib\\contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304\n         [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_1, Reshape_1/shape)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"cnn.py\", line 70, in \n    _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304\n         [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_1, Reshape_1/shape)]]\n\nCaused by op 'Reshape_1', defined at:\n  File \"cnn.py\", line 50, in \n    model_op = model()\n  File \"cnn.py\", line 43, in model\n    maxpool_reshaped = tf.reshape(maxpool_out2, [-1,w3.get_shape().as_list()[0]])\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2448, in reshape\n    name=name)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304\n         [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MaxPool_1, Reshape_1/shape)]]\n\nEDIT-1\n\nGot this new error after modifying based on those edits:\n\npythonCopyx_reshaped = tf.reshape(x, shape=[-1,150,150,1])\nbatch_size = x_reshaped.get_shape().as_list()[0]\n\n... Same code as above ...\n\nmaxpool_reshaped = tf.reshape(maxpool_out2, [batch_size, -1])\n\nError:\n\npythonCopyTraceback (most recent call last):\n  File \"cnn.py\", line 52, in \n    model_op = model()\n  File \"cnn.py\", line 45, in model\n    maxpool_reshaped = tf.reshape(maxpool_out2, [batch_size, -1])\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2448, in reshape\n    name=name)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 493, in apply_op\n    raise err\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 490, in apply_op\n    preferred_dtype=default_dtype)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 669, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 176, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 165, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\", line 441, in make_tensor_proto\n    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\", line 441, in \n    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\", line 65, in as_bytes\n    (bytes_or_text,))\nTypeError: Expected binary or unicode string, got None\n\nEDIT-2\n\nAfter doing the following edits (in addtion to removing batch_size:\n\npythonCopyw3 = tf.Variable(tf.random_normal([361, 256])) \n...\n...\nw_out = tf.Variable(tf.random_normal([256, 2])) \n\nI'm having the following error:\n\npythonCopyEPOCH 0\nW c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:975] Invalid argument: logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]\n         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_2, Reshape_3)]]\nTraceback (most recent call last):\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1021, in _do_call\n    return fn(*args)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1003, in _run_fn\n    status, run_metadata)\n  File \"C:\\Python35\\lib\\contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 469, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]\n         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_2, Reshape_3)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"cnn.py\", line 73, in \n    _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 766, in run\n    run_metadata_ptr)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 964, in _run\n    feed_dict_string, options, run_metadata)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1014, in _do_run\n    target_list, options, run_metadata)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1034, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]\n         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_2, Reshape_3)]]\n\nCaused by op 'SoftmaxCrossEntropyWithLogits', defined at:\n  File \"cnn.py\", line 55, in \n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model_op, y))\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1449, in softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 2265, in _softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]\n         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_2, Reshape_3)]]\n\nEDIT-3\n\nThis is how the binary (pickled) file looks like [label, filename, data]:\n\npythonCopy[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array(['1.jpg', '10.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg',\n       '7.jpg', '8.jpg', '9.jpg'], \n      dtype='<U6'), array([[142, 138, 134, ..., 128, 125, 122],\n       [151, 151, 149, ..., 162, 159, 157],\n       [120, 121, 122, ..., 132, 128, 122],\n       ..., \n       [179, 175, 177, ..., 207, 205, 203],\n       [126, 129, 130, ..., 134, 130, 134],\n       [165, 170, 175, ..., 193, 193, 187]])]\n\nHow can I solve this issue?",
    "answer": "Let's come to your original error:\n\n  Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304\n\nThis is because you adapt your code from a code with original input image size 24*24. The tensor shape after two convolution and two max-pooling layers is [-1, 6, 6, 64]. However, as your input image shape is 150*150, the intermediate shape becomes [-1, 38, 38, 64].\n\ntry change w3\n\n  w3 = tf.Variable(tf.random_normal([38*38*64, 1024]))\n\nYou should always keep an eye on your tensor shape flow.",
    "mlApiName": "tf.nn.softmax_cross_entropy_with_logits",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-2",
      "leafContractCategory": "IC-2",
      "rootCause": "Missing Input Value/Type Dependency",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I can't seem to be able to restore saved variables when using TensorFlow in a Jupyter notebook. I train an ANN, then I run saver.save(sess, \"params1.ckpt\") then I train it again, save the new result saver.save(sess, \"params2.ckpt\") but when I run saver.restore(sess, \"params1.ckpt\") my model doesn't load the values saved on params1.ckpt and keeps those in params2.ckpt.\n\nIf I run the model, save it on params.ckpt, then close and halt, then try to load it again, I get the following error:\n\npythonCopy---------------------------------------------------------------------------\nStatusNotOK                               Traceback (most recent call last)\nStatusNotOK: Not found: Tensor name \"Variable/Adam\" not found in checkpoint files params.ckpt\n     [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]\n\nDuring handling of the above exception, another exception occurred:\n\nSystemError                               Traceback (most recent call last)\n in ()\n----> 1 saver.restore(sess, \"params.ckpt\")\n\n/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)\n    889       save_path: Path where parameters were previously saved.\n    890     \"\"\"\n--> 891     sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})\n    892 \n    893 \n\n/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict)\n    366 \n    367     # Run request and get response.\n--> 368     results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n    369 \n    370     # User may have fetched the same tensor multiple times, but we\n\n/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, target_list, fetch_list, feed_dict)\n    426 \n    427       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n--> 428                                target_list)\n    429 \n    430     except tf_session.StatusNotOK as e:\n\nSystemError:  returned a result with an error set\n\nMy code for training is:\n\npythonCopydef weight_variable(shape, name):\n  initial = tf.truncated_normal(shape, stddev=1.0, name=name)\n  return tf.Variable(initial)\n\ndef bias_variable(shape, name):\n  initial = tf.constant(1.0, shape=shape)\n  return tf.Variable(initial, name=name)\n\ninput_file = pd.read_csv('P2R0PC0.csv') \nfeatures = #vector with 5 feature names\ntargets = #vector with 4 feature names\nx_data = input_file.as_matrix(features)\nt_data = input_file.as_matrix(targets)\n\nx = tf.placeholder(tf.float32, [None, x_data.shape[1]])\n\nhiddenDim = 5\n\nb1 = bias_variable([hiddenDim], name = \"b1\")\nW1 = weight_variable([x_data.shape[1], hiddenDim], name = \"W1\")\n\nb2 = bias_variable([t_data.shape[1]], name = \"b2\")\nW2 = weight_variable([hiddenDim, t_data.shape[1]], name = \"W2\")\n\nhidden = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\ny = tf.nn.sigmoid(tf.matmul(hidden, W2) + b2)\nt = tf.placeholder(tf.float32, [None, t_data.shape[1]])\n\nlambda1 = 1\nbeta1 = 1\nlambda2 = 1\nbeta2 = 1\nerror = -tf.reduce_sum(t * tf.log(tf.clip_by_value(y,1e-10,1.0)) + (1 - t) * tf.log(tf.clip_by_value(1 - y,1e-10,1.0)))\ncomplexity = lambda1 * tf.nn.l2_loss(W1) + beta1 * tf.nn.l2_loss(b1) + lambda2 * tf.nn.l2_loss(W2) + beta2 * tf.nn.l2_loss(b2)\nloss = error + complexity\n\ntrain_step = tf.train.AdamOptimizer(0.001).minimize(loss)\nsess = tf.Session()\n\ninit = tf.initialize_all_variables()\nsess.run(init)\n\nran = 25001\ndelta = 250\n\nplot_data = np.zeros(int(ran / delta + 1))\nk = 0;\nfor i in range(ran):\n    train_step.run({x: data, t: labels}, sess)\n    if i % delta == 0:\n        plot_data[k] = loss.eval({x: data, t: labels}, sess)\n        #plot_training[k] = loss.eval({x: x_test, t: t_test}, sess)\n        print(str(plot_data[k]))\n        k = k + 1\n\nplt.plot(np.arange(start=2, stop=int(ran / delta + 1)), plot_data[2:])\n\nsaver = tf.train.Saver()\nsaver.save(sess, \"params.ckpt\")\n\nerror.eval({x:data, t: labels}, session=sess)\n\nAm I doing anything wrong? Why can't I ever restore my variables?",
    "answer": "It looks like you are using Jupyter to build your model. One possible issue, when constructing a tf.Saver with the default arguments is that it will use the (auto-generated) names for the variables as the keys in your checkpoint. Since in Jupyter its easy to re-execute code cells multiple times, you might be ending up with multiple copies of the variable nodes in the session that you save. See my answer to this question for an explanation of what can go wrong.\n\nThere are a few possible solutions. Here are the easiest:\n\nCall tf.reset_default_graph() before you build your model (and the Saver). This will ensure that the variables get the names you intended, but it will invalidate previously-created graphs.\nUse explicit arguments to tf.train.Saver() to specify the persistent names for the variables. For your example this shouldn't be too hard (though it becomes unwieldy for larger models):\n\npythonCopysaver = tf.train.Saver(var_list={\"b1\": b1, \"W1\": W1, \"b2\": b2, \"W2\": W2})\n\nCreate a new tf.Graph() and make it the default each time you create the model. This can be tricky in Jupyter, since it forces you to put all of the model building code in one cell, but it works well for scripts:\n\npythonCopywith tf.Graph().as_default():\n  # Model building and training/evaluation code goes here.",
    "mlApiName": "tf.Graph.as_default,tf.Session.run,tf.reset_default_graph,tf.train.Saver.save",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,IC-1,F",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "In ipython I imported tensorflow as tf and numpy as np and created an TensorFlow InteractiveSession.\nWhen I am running or initializing some normal distribution with numpy input, everything runs fine:\n\npythonCopysome_test = tf.constant(np.random.normal(loc=0.0, scale=1.0, size=(2, 2)))\nsession.run(some_test)\n\nReturns:\n\npythonCopyarray([[-0.04152317,  0.19786302],\n       [-0.68232622, -0.23439092]])\n\nJust as expected.\n\n...but when I use the Tensorflow normal distribution function:\n\npythonCopysome_test = tf.constant(tf.random_normal([2, 2], mean=0.0, stddev=1.0, dtype=tf.float32))\nsession.run(some_test)\n\n...it raises a Type error saying:\n\npythonCopy(...)\nTypeError: List of Tensors when single Tensor expected\n\nWhat am I missing here?\n\nThe output of:\n\npythonCopysess.run(tf.random_normal([2, 2], mean=0.0, stddev=1.0, dtype=tf.float32))\n\nalone returns the exact same thing which np.random.normal generates -> a matrix of shape (2, 2) with values taken from a normal distribution.",
    "answer": "The tf.constant() op takes a numpy array (or something implicitly convertible to a numpy array), and returns a tf.Tensor whose value is the same as that array. It does not accept a tf.Tensor as its argument.\n\nOn the other hand, the tf.random_normal() op returns a tf.Tensor whose value is generated randomly according to the given distribution each time it runs. Since it returns a tf.Tensor, it cannot be used as the argument to tf.constant(). This explains the TypeError (which is unrelated to the use of tf.InteractiveSession, since it occurs when you build the graph).\n\nI'm assuming you want your graph to include a tensor that (i) is randomly generated on its first use, and (ii) constant thereafter. There are two ways to do this:\n\nUse NumPy to generate the random value and put it in a tf.constant(), as you did in your question:\n\npythonCopysome_test = tf.constant(\n    np.random.normal(loc=0.0, scale=1.0, size=(2, 2)).astype(np.float32))\n\n(Potentially faster, as it can use the GPU to generate the random numbers) Use TensorFlow to generate the random value and put it in a tf.Variable:\n\npythonCopysome_test = tf.Variable(\n    tf.random_normal([2, 2], mean=0.0, stddev=1.0, dtype=tf.float32)\nsess.run(some_test.initializer)  # Must run this before using `some_test`",
    "mlApiName": "tf.Session.run,tf.Variable,tf.constant",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "MT,F,IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I am using a Tensorflow tf.Saver to load a pre-trained model and I want to re-train a few of its layers by erasing (re-initializing to random) their appropriate weights and biases, then training those layers and saving the trained model. I can not find a method that re-initializes the variables. I tried tf.initialize_variables(fine_tune_vars) but it did not work (I'd assume because the variables are already initialized), I have also seen that you can pass variables to the tf.Saver so that you partially load the model, however that is half of what I want to achieve (because when I save the trained model, I want it to save all variables not only the ones I loaded).\n\nThank you in advance!",
    "answer": "initialize_all_variables should work to re-initialize previously initialized var.\n\nJust did this sanity check in 0.10\n\npythonCopytf.reset_default_graph()\na = tf.Variable(tf.ones_initializer(()))\ninit_op = tf.initialize_all_variables()\nmodify_op = a.assign(5.0)\n\nsess = tf.InteractiveSession()\nsess.run(init_op)\nprint(a.eval())\nsess.run(modify_op)\nprint(a.eval())\nsess.run(init_op)\nprint(a.eval())\n\nResult\n\npythonCopy1.0\n5.0\n1.0",
    "mlApiName": "tf.Graph.get_default_graph.get_tensor_by_name,tf.Session.run,tf.train.import_meta_graph",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,IC-1,F,IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I'm trying to split my input layer into different sized parts. I'm trying to use tf.slice to do that but it's not working.\n\nSome sample code:\n\npythonCopyimport tensorflow as tf\nimport numpy as np\n\nph = tf.placeholder(shape=[None,3], dtype=tf.int32)\n\nx = tf.slice(ph, [0, 0], [3, 2])\n\ninput_ = np.array([[1,2,3],\n                   [3,4,5],\n                   [5,6,7]])\n\nwith tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        print sess.run(x, feed_dict={ph: input_})\n\nOutput:\n\npythonCopy[[1 2]\n [3 4]\n [5 6]]\n\nThis works and is roughly what I want to happen, but I have to specify the first dimension (3 in this case). I can't know though how many vectors I'll be inputting, that's why I'm using a placeholder with None in the first place!\n\nIs it possible to use slice in such a way that it will work when a dimension is unknown until runtime?\n\nI've tried using a placeholder that takes its value from ph.get_shape()[0] like so: x = tf.slice(ph, [0, 0], [num_input, 2]). but that didn't work either.",
    "answer": "You can specify one negative dimension in the size parameter of tf.slice. The negative dimension tells Tensorflow to dynamically determine the right value basing its decision on the other dimensions.\n\npythonCopyimport tensorflow as tf\nimport numpy as np\n\nph = tf.placeholder(shape=[None,3], dtype=tf.int32)\n\n# look the -1 in the first position\nx = tf.slice(ph, [0, 0], [-1, 2])\n\ninput_ = np.array([[1,2,3],\n                   [3,4,5],\n                   [5,6,7]])\n\nwith tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        print(sess.run(x, feed_dict={ph: input_}))",
    "mlApiName": "tf.train.Saver,tf.train.Saver.save",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "G,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "Suppose I have a Tensorflow tensor. How do I get the dimensions (shape) of the tensor as integer values? I know there are two methods, tensor.get_shape() and tf.shape(tensor), but I can't get the shape values as integer int32 values.\n\nFor example, below I've created a 2-D tensor, and I need to get the number of rows and columns as int32 so that I can call reshape() to create a tensor of shape (num_rows * num_cols, 1). However, the method tensor.get_shape() returns values as Dimension type, not int32.\n\npythonCopyimport tensorflow as tf\nimport numpy as np\n\nsess = tf.Session()    \ntensor = tf.convert_to_tensor(np.array([[1001,1002,1003],[3,4,5]]), dtype=tf.float32)\n\nsess.run(tensor)    \n# array([[ 1001.,  1002.,  1003.],\n#        [    3.,     4.,     5.]], dtype=float32)\n\ntensor_shape = tensor.get_shape()    \ntensor_shape\n# TensorShape([Dimension(2), Dimension(3)])    \nprint tensor_shape    \n# (2, 3)\n\nnum_rows = tensor_shape[0] # ???\nnum_cols = tensor_shape[1] # ???\n\ntensor2 = tf.reshape(tensor, (num_rows*num_cols, 1))    \n# Traceback (most recent call last):\n#   File \"\", line 1, in \n#   File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1750, in reshape\n#     name=name)\n#   File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 454, in apply_op\n#     as_ref=input_arg.is_ref)\n#   File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 621, in convert_to_tensor\n#     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n#   File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 180, in _constant_tensor_conversion_function\n#     return constant(v, dtype=dtype, name=name)\n#   File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 163, in constant\n#     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n#   File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 353, in make_tensor_proto\n#     _AssertCompatible(values, dtype)\n#   File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 290, in _AssertCompatible\n#     (dtype.name, repr(mismatch), type(mismatch).__name__))\n# TypeError: Expected int32, got Dimension(6) of type 'Dimension' instead.",
    "answer": "To get the shape as a list of ints, do tensor.get_shape().as_list().\n\nTo complete your tf.shape() call, try tensor2 = tf.reshape(tensor, tf.TensorShape([num_rows*num_cols, 1])). Or you can directly do tensor2 = tf.reshape(tensor, tf.TensorShape([-1, 1])) where its first dimension can be inferred.",
    "mlApiName": " tf.scatter_update",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "RT",
      "leafContractCategory": "RT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I have thought that variable assignments are done after all operations in a list given to sess.run, but the following code returns different results at different execution. It seems randomly run operations in the list and assign the variable after the run of the operation in the list.\n\npythonCopya = tf.Variable(0)\nb = tf.Variable(1)\nc = tf.Variable(1)\nupdate_a = tf.assign(a, b + c)\nupdate_b = tf.assign(b, c + a)\nupdate_c = tf.assign(c, a + b)\n\nwith tf.Session() as sess:\n  sess.run(initialize_all_variables)\n  for i in range(5):\n    a_, b_, c_ = sess.run([update_a, update_b, update_c])\n\nI'd like to know the timing of variable assignments.\nWhich are correct: \"update_x -> assign x -> ... -> udpate_z -> assign z\" or \"update_x -> udpate_y -> udpate_z -> assign a, b, c\"? (where (x, y, z) is a permutation of (a, b, c))\nIn addition, if there is a way that realize the latter assignment (assignment are done after all operations in the list are done), please let me know how to realize it.",
    "answer": "The three operations update_a, update_b, and update_c have no interdependencies in the dataflow graph, so TensorFlow may choose to execute them in any order. (In the current implementation, it is possible that all three of them will be executed in parallel on different threads.) A second nit is that reads of variables are cached by default, so in your program the value assigned in update_b (i.e. c + a) may use the original or the updated value of a, depending on when the variable is first read.\n\nIf you want to ensure that the operations happen in a particular order, you can use with tf.control_dependencies([...]): blocks to enforce that operations created within the block happen after operations named in the list.  You can use tf.Variable.read_value() inside a with tf.control_dependencies([...]): block to make the point at which the variable is read explicit.\n\nTherefore, to if you want to ensure that update_a happens before update_b and update_b happens before update_c, you could do:\n\npythonCopyupdate_a = tf.assign(a, b + c)\n\nwith tf.control_dependencies([update_a]):\n  update_b = tf.assign(b, c + a.read_value())\n\nwith tf.control_dependencies([update_b]):\n  update_c = tf.assign(c, a.read_value() + b.read_value())",
    "mlApiName": "tf.io.decode_raw",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "PT",
      "leafContractCategory": "PT",
      "rootCause": "Unacceptable Input Type",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I would like to replace or modify the gradient of an op or portion of the graph in tensorflow.  It would be ideal if I can use the existing gradient in the calculation.\n\nIn some ways this is the opposite to what tf.stop_gradient() does: instead of adding a calculation which is ignored when calculating gradients, I want a calculation which is only used when calculating gradients.\n\nA simple example would be something which simply scales gradients by multiplying them with a constant (but does not multiply the forward calculation by a constant).  Another example would be something which clips the gradients to a given range.",
    "answer": "For TensorFlow 1.7 and TensorFlow 2.0 look at edit blow.\n\nFirst define your custom gradient:\n\npythonCopy@tf.RegisterGradient(\"CustomGrad\")\ndef _const_mul_grad(unused_op, grad):\n  return 5.0 * grad\n\nSince you want nothing to happen in the forward pass, override the gradient of an identity operation with your new gradient:\n\npythonCopyg = tf.get_default_graph()\nwith g.gradient_override_map({\"Identity\": \"CustomGrad\"}):\n  output = tf.identity(input, name=\"Identity\")\n\nHere is a working example with a layer that clips gradients in the backwards pass and does nothing in the forwards pass, using the same method:\n\npythonCopyimport tensorflow as tf\n\n@tf.RegisterGradient(\"CustomClipGrad\")\ndef _clip_grad(unused_op, grad):\n  return tf.clip_by_value(grad, -0.1, 0.1)\n\ninput = tf.Variable([3.0], dtype=tf.float32)\n\ng = tf.get_default_graph()\nwith g.gradient_override_map({\"Identity\": \"CustomClipGrad\"}):\n  output_clip = tf.identity(input, name=\"Identity\")\ngrad_clip = tf.gradients(output_clip, input)\n\n# output without gradient clipping in the backwards pass for comparison:\noutput = tf.identity(input)\ngrad = tf.gradients(output, input)\n\nwith tf.Session() as sess:\n  sess.run(tf.global_variables_initializer())\n  print(\"with clipping:\", sess.run(grad_clip)[0])\n  print(\"without clipping:\", sess.run(grad)[0])\n\nEdit for TensorFlow 1.7 and TensorFlow 2.0\n\nSince 1.7 there is a new way to redefine the gradient with shorter syntax, which also works with Tensorflow 2.0. It also allows to redefine the gradient of multiple operations at the same time. Here are the examples from above, rewritten for TensorFlow 1.7 and TensorFlow 2.0:\n\nLayer that scales gradients in the backward pass:\n\npythonCopy@tf.custom_gradient\ndef scale_grad_layer(x):\n  def grad(dy):\n    return 5.0 * dy\n  return tf.identity(x), grad\n\nExample with a layer that clips gradients in the backward pass:\n\npythonCopy@tf.custom_gradient\ndef clip_grad_layer(x):\n  def grad(dy):\n    return tf.clip_by_value(dy, -0.1, 0.1)\n  return tf.identity(x), grad",
    "mlApiName": "tf.linalg.matmul,tf.nn.max_pool",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "IC-2,F",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "",
    "title": "",
    "question": "I have omitted unnecessary code snippets to keep the question details clean. I am trying to plot both training and test model curves.  I am able to store the training loss and accuracy curves. But, when writing using test_writer, I am getting the following error:\n\npythonCopytest_writer.add_summary(test_summary,step*batch_size)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/summary/writer/writer.py\", line 123, in add_summary\n    for value in summary.value:\nAttributeError: 'list' object has no attribute 'value'\n\nCode:\n\npythonCopyaccuracy = tf.reduce_mean(correct_prediction)\n\n#Summary\ntf.summary.scalar(\"loss\",cross_entropy)\naccuracy_summary = tf.summary.scalar(\"accuracy\",accuracy)\n\nmerged_summary_op = tf.summary.merge_all()\ntrain_writer = tf.summary.FileWriter(graph_location)\ntrain_writer.add_graph(tf.get_default_graph())\ntest_writer = tf.summary.FileWriter(location)\ntest_writer.add_graph(tf.get_default_graph())\n\nwith  tf.Session() as sess:\n    print \"STARTED TENSORLFOW SESSION\"\n    sess.run(tf.initialize_all_variables())\n    while step*batch_size < training_iters:\n        if count <= 900:\n            _,summary = sess.run([train_step,merged_summary_op], feed_dict={x:batch_xs, j:batch_js, y_:batch_ys, keep_prob:dropout})\n            train_writer.add_summary(summary, step*batch_size)\n        else:\n            test_summary = sess.run([accuracy_summary], feed_dict={x:test_xs,j:test_js,y_:test_ys, keep_prob: 0.5})\n            test_writer.add_summary(test_summary,step*batch_size)\n\nMy training curves are plotted fine. My testing curves work if I change it to \ntest_summary = sess.run([train_step,merged_summary_op], feed_dict={x:test_xs,j:test_js,y_:test_ys, keep_prob: 0.5}) but it doesn't make sense as I would not want to train my optimizer by feeding the test set.\n\nWhat is it that I am missing here?",
    "answer": "I think you should just rewrite the penultimate line from\n\npythonCopytest_summary = sess.run([accuracy_summary], feed_dict={x:test_xs,j:test_js,y_:test_ys, keep_prob: 0.5})\n\nto\n\npythonCopytest_summary = sess.run(accuracy_summary, feed_dict={x:test_xs,j:test_js,y_:test_ys, keep_prob: 0.5})\n\nin order to have a scalar output and not a list.",
    "mlApiName": "tf.estimator.DNNClassifier,tf.estimator.DNNClassifier.train",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "IC-1,IC-1",
      "leafContractCategory": "SAM(Level-3)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": ""
    }
  }
]